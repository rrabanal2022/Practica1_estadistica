---
title: "Práctica 1 estadística"
author: "Ramón Martínez, Rodrigo Rabanal"
format:
  html:
    theme: minty
    css: estilos.css
editor: visual
toc: true
toc-location: left
toc-depth: 2
---

<img src="logo.png" class="logo"/>

# 1. EXPLORACIÓN INICIAL

Antes de empezar, cargamos las librerías que vamos a usar.

```{r}

library(dplyr)
library(mice)
library(VIM)
library(naniar)
library(car)
library(splines)

```

Empezaremos planteando una visualización de los datos, para entender la naturaleza de las variables y ver los valores con los que trabajaremos.

```{r}
datos <- read.csv("athletics_B.csv")

summary(datos)

str(datos)
```

Vamos a realizar un pequeño análisis exploratorio de datos, atendiendo a diferentes aspectos de los mismos.

## 1. Media, medianay desviación típica

En primer lugar, calcularemos la media, la mediana y la desviación típica del índice de rendimiento de los jugadores.

```{r}
#Calculamos la media del índice de rendimiento de los jugadores

media_performance <- mean(datos$performance_index, na.rm = TRUE)

#Devolvemos el valor calculado

media_performance

#Calculamos la mediana del índice de rendimiento de los jugadores

mediana_performance <- median(datos$performance_index, na.rm = TRUE)

#Devolvemos el valor calculado

mediana_performance

#Calculamos la desviación típica del índice de rendimiento de los jugadores

dtip_performance <- sd(datos$performance_index, na.rm = TRUE)

#Devolvemos el valor calculado

dtip_performance

```

Se aprecia una media y una mediana parecidas, lo que parece indicar que la mayoría de jugadores se encuentran en un estado de forma relativamente similar.

## 2. Histograma de la variable *performance_index*

```{r}
#Vamos a hacer un histograma del índice de rendimiento de los jugadores en 20 intervalos

# Histograma de performance_index con 20 intervalos
hist(datos$performance_index,
     breaks = 20,            
     main = "Histograma de Performance Index",  
     xlab = "Performance Index",                
     ylab = "Frecuencia",                       
     col = "skyblue",                           
     border = "white",
     freq = FALSE) 

lines(density(datos$performance_index),
      col = "red",
      lwd = 2)  

cuartiles <- quantile(datos$performance_index, probs = c(0.25, 0.5, 0.75))

# Añadimos líneas verticales discontinuas en los cuartiles
abline(v = cuartiles, 
       col = "darkgreen", 
       lty = 2,      # tipo de línea discontinua
       lwd = 2)      # grosor


```

En el histograma, podemos apreciar que la variable *performance_index* sigue una distribución normal.

La línea roja marca la distribución, mientras que las líneas verdes discontinuas marcan los valores de los cuartiles; entre los que se encuentra el 50% de la muestra para esta variable.

Esto complementa a lo que hemos deducido previamente a partir de los datos de la media y la mediana.

## 3. Distribución de frecuencias relativas

```{r}
#Vamos a calcular la distribución de las frecuencias relativas de los jugadores por posición

frecuencia <- table(datos$position)

frecuencia_relativa <- prop.table(frecuencia)

# Mostrar la tabla con frecuencias absolutas y relativas (en porcentaje)
tabla_frecuencias <- data.frame(
  Posición = names(frecuencia),
  Frecuencia = as.vector(frecuencia),
  Frecuencia_Relativa = round(as.vector(frecuencia_relativa) * 100, 2)
)

# Mostrar resultados
tabla_frecuencias

```

Podemos observar que la frecuencia relativa de porteros es mucho menor que la del resto de posiciones. Esto se debe a que en un equipo juega un solo portero para los 3 o 4 defensas, 3 o 4 mediocentros y 2 o 3 delanteros. Por tanto, es lógico obtener ese valor. Caso análogo, pero en menor medida para los delanteros, que suponen un número inferior en la plantilla que los mediocentros y los defensas.

## 4. Diagrama de cajas de *performace_index* según el equipo

```{r}

# Diagrama de cajas de performance_index según team
boxplot(performance_index ~ team, 
        data = datos,
        main = "Diagrama de Cajas de Performance Index por Equipo",
        xlab = "Equipo",
        ylab = "Performance Index",
        col = c("lightblue", "lightgreen", "lightpink", "khaki"),
        border = "darkgray",
        notch = TRUE)

```

En este *boxplot* podemos ver que en el equipo B hay una mayor variabilidad de resultados, pues los cuartiles son más grandes que los de los equipos A y B (que tienen niveles más similares de rendimiento). Sin embargo, la mediana del equipo B es claramente mayor que la del resto de equipos.

Esto puede indicar un mayor nivel de algunos jugadores del equipo B con respecto de los jugadores del resto de equipos, pero también entre los jugadores del mismo equipo (mucha diferencia entre jugadores "estrellas" y el resto).

Por último, en el equipo C tienen todos los jugadores un nivel muy similar; lo que podría provocar que el rendimiento medio sea mayor.

## 5. Gráfico de dispersión entre *training_hours* y *performance_index*

```{r}
#Construimos un gráfico de dispersión entre training_hours y performance_index
plot(datos$training_hours, datos$performance_index,
     main = "Relación entre horas de entrenamiento y rendimiento",
     xlab = "Horas de entrenamiento (training_hours)",
     ylab = "Índice de rendimiento (performance_index)",
     pch = 19,               # tipo de punto sólido
     col = "steelblue",      # color de los puntos
     cex = 1.2)              # tamaño de los puntos

# Agregar una línea de tendencia (regresión lineal)
abline(lm(performance_index ~ training_hours, data = datos), 
       col = "red", lwd = 2)
```

Se aprecia linealidad en el modelo. Hay una clara relación lineal entre las horas de entrenamiento y el índice de rendimiento, apreciando un mayor rendimiento conforme aumentan las horas de entrenamiento.

## 6. Matriz de correlaciones

```{r}
#Calculamos la matriz de correlaciones entre variables numéricas
datos_numericos <- datos[, sapply(datos, is.numeric)]

# Calcular la matriz de correlaciones
matriz_cor <- cor(datos_numericos, use = "complete.obs")

# Mostrar la matriz de correlaciones
matriz_cor

#Vamos a visualizarla
library(corrplot)

corrplot(matriz_cor, method = "color", type = "upper",
         tl.col = "black", tl.cex = 0.8, 
         addCoef.col = "black", number.cex = 0.4)

```

Aquí podemos ver la matriz de correlaciones. Vemos que las variables que presentan más correlación son los pases realizados con éxito y los pases intentados. Otras variables que presentan cierta correlación son el índice de rendimiento con la edad y las horas de entrenamiento.

## 7. Gráfico de dispersión entre fatiga e índice de rendimiento

```{r}

#Representamos un gráfico de dispersión entre training_hours y performance_index
library(ggplot2)

ggplot(datos, aes(x = fatigue, y = performance_index)) +
  geom_point(color = "steelblue", size = 2) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Relación entre fatiga e índice de rendimiento",
       x = "Fatiga",
       y = "Índice de rendimiento") +
  theme_minimal()

```

Parece que hay una relación lineal entre ambas variables. En particular, podemos observar que parece haber una relación que indica una menor índice de rendimiento conforme la fatiga incrementa.

## 8. Boxplot del índice de rendimiento por posición

```{r}
#Realizamos un boxplot de performance_index por posicion

boxplot(performance_index ~ position,
        data = datos,
        main = "Diagrama de Cajas de Performance Index por Posición",
        xlab = "Posición",
        ylab = "Performance Index",
        col = c("lightblue", "lightgreen", "lightpink", "khaki"),
        border = "gray40",
        notch = TRUE)


```

Se aprecian una serie de diferencias entre puestos, que procederemos a desarrollar. En primer lugar, no hay grandes diferencias en lo referente a la media del índice de rendimiento en función de la posición. Por otro lado, vemos que el tercer cuartil de los defensas es más pequeño que el resto, dando a entender que se encuentran más agrupados en esas zonas de rendimiento; destacando menos que en otras posiciones. Además, hay tres outliers con valores muy bajos de rendimiento. Finalmente, el último valor remarcable es el del portero, donde vemos que el "bigote" es de longitud mucho menor que el del resto de posiciones.

## 9. Valores atípicos en *agility_time*

```{r}
# Vamos a identificar los valores atípicos en agility_time 

# Calculamos los cuartiles y el rango intercuartílico
Q1 <- quantile(datos$agility_time, 0.25, na.rm = TRUE)
Q3 <- quantile(datos$agility_time, 0.75, na.rm = TRUE)
IQR_value <- IQR(datos$agility_time, na.rm = TRUE)

# Límites inferior y superior para detectar atípicos
lim_inf <- Q1 - 1.5 * IQR_value
lim_sup <- Q3 + 1.5 * IQR_value

# Identificamos los valores atípicos
outliers <- datos$agility_time[datos$agility_time < lim_inf | datos$agility_time > lim_sup]

# Mostramos resultados
outliers

```

Vemos que por la regla del rango intercuartílico (IQR) hay 5 valores atípicos, que se corresponden con NA. Es decir, valores no recogidos de esta variable para ciertos jugadores. Vamos a hacer un boxplot para intentar ver más posibles valores atípicos, donde estos hayan sido recogidos.

```{r}
boxplot(datos$agility_time,
        main = "Detección de valores atípicos en Agility Time",
        ylab = "Agility Time",
        col = "lightblue",
        border = "gray40")

```

La conclusión del boxplot es la misma. No hay valores atípicos en la variable agility_time, más allá de los valores no recogidos.

## 10. Proporción de jugadores zurdos en la base de datos

```{r}

# Calculamos la proporción de jugadores zurdos
proporcion_zurdos <- mean(datos$left_footed == 1, na.rm = TRUE)

# Mostramos el resultado en porcentaje
proporcion_zurdos * 100


```

Como podemos ver, el 29,17% de los jugadores de la base de datos son zurdos.

# 2. MANEJO DE VALORES FALTANTES

## 1. Identificación de variables con valores faltantes

Primero, vemos qué columnas tienen valores NA

```{r}

# Ver columnas que contienen al menos un NA
colnames(datos)[colSums(is.na(datos)) > 0]


```

Las variables *training_hours*, *sleep_hours*, *fatigue*, *strength_1RM* y *agility_time* tienen valores faltantes.

Ahora, veremos cuántos valores faltan en cada una

```{r}
# Cantidad de NA solo en columnas donde hay al menos uno
na_counts <- colSums(is.na(datos))
na_counts[na_counts > 0]


```

Así, vemos que hay 5 valores faltantes en cada una de estas variables.

## 2. Calculamos la proporción de valores faltantes sobre el dataset completo

```{r}

# Porcentaje total de NA
mean(is.na(datos)) * 100


```

Es decir, el 0.25% de los valores del dataset son valores faltantes.

## 3. Resumen de combina las variables con missing y su porcentaje de valores ausentes

```{r}

# Calcular cantidad y porcentaje de NA por variable
na_table <- data.frame(
  variable = colnames(datos),
  na_count = colSums(is.na(datos)),
  na_percent = (1- colMeans(is.na(datos)) * 100)
)

# Filtrar solo variables con al menos un NA
na_table <- na_table[na_table$na_count > 0, ]

# Mostrar tabla
na_table


```

## 4. Imputación por la media en *training_hours*

```{r}

# Calculamos la media de training_hours ignorando NA
media_training <- mean(datos$training_hours, na.rm = TRUE)

# Imputamos los NA con la media
training_hours_imputada <- datos$training_hours
training_hours_imputada[is.na(training_hours_imputada)] <- media_training

# Calculamos de nuevo la media después de imputar
nueva_media_training <- mean(training_hours_imputada)

# Comprobamos que el valor es el mismo
media_training
nueva_media_training


```

Con esto, hemos sustituido los valores faltantes de la variable *training_hours* con la media de los valores de esta variable.

## 5. Histogramas de *sleep_hours* antes y después de la imputación por la media

En primer lugar, trabajaremos con la variable sin imputar (con valores faltantes).

```{r}

# Guardamos una copia de la variable original
sleep_original <- datos$sleep_hours

# Calculamos la media sin NA
media_sleep <- mean(datos$sleep_hours, na.rm = TRUE)

```

A continuación, trabajaremos con la versión imputada.

```{r}

# Creamos la versión imputada
sleep_imputada <- datos$sleep_hours
sleep_imputada[is.na(sleep_imputada)] <- media_sleep

```

Ahora, podemos desarrollar los histogramas.

```{r}

# Histogramas antes y después
par(mfrow = c(1, 2))  # Mostrar dos gráficos juntos

hist(sleep_original,
     main = "Sleep Hours - Antes imputación",
     xlab = "Horas de sueño")

hist(sleep_imputada,
     main = "Sleep Hours - Después imputación con media",
     xlab = "Horas de sueño")


```

Como podemos ver, no se aprecian diferencias aparentes. Esto se debe al hecho de que, al imputar los valores faltantes por la media, no modificamos la estructura presente de la variable. Así, el único cambio aparente es un aumento de la frecuencia para los valores cercanos a la mediana (asumimos que son los imputados). Sin embargo, como afirmamos, la distribución es la misma.

## 6. Imputación por la mediana en *fatigue* y comparación con imputación con la media.

En primer lugar, imputamos los valores por la mediana en la variable *fatigue*.

```{r}
# Calculamos la mediana ignorando NA
mediana_fatigue <- median(datos$fatigue, na.rm = TRUE)

# Crear una nueva variable con la imputación
fatigue_imputada <- datos$fatigue
fatigue_imputada[is.na(fatigue_imputada)] <- mediana_fatigue

# Comprobamos que ya no hay NA
sum(is.na(fatigue_imputada))


```

A continuación, hacemos la imputación por la media.

```{r}

# Calcular la media ignorando NA
media_fatigue <- mean(datos$fatigue, na.rm = TRUE)

# Crear nueva variable imputada por la media
fatigue_imputada_media <- datos$fatigue
fatigue_imputada_media[is.na(fatigue_imputada_media)] <- media_fatigue

# Comprobar la imputación
sum(is.na(fatigue_imputada_media))  


```

Ahora, porcedemos a comparar estas nuevas variables creadas.

Para ello, empezaremos comparando estadísticas básicas mediante una tabla

```{r}

# Media original (ignorando NA)
media_original <- mean(datos$fatigue, na.rm = TRUE)

# Media tras imputación por mediana
media_median <- mean(fatigue_imputada, na.rm = TRUE)

# Media tras imputación por media
media_mean <- mean(fatigue_imputada_media, na.rm = TRUE)

# Mediana original
mediana_original <- median(datos$fatigue, na.rm = TRUE)

# Mediana tras imputación por mediana
mediana_median <- median(fatigue_imputada, na.rm = TRUE)

# Mediana tras imputación por media
mediana_mean <- median(fatigue_imputada_media, na.rm = TRUE)

data.frame(
  Version = c("Original", "Imputación Mediana", "Imputación Media"),
  Media = c(media_original, media_median, media_mean),
  Mediana = c(mediana_original, mediana_median, mediana_mean)
)


```

De esta manera, vemos que la imputación por la mediana modifica ligeramente la media de la variable; mientras que el valor de la mediana permanece intacto en cualquier caso.

Vamos a ver si este cambio es significativo. Para ello, haremos un *t-test*, cuya hipótesis nula será que el cambio no es significativo.

```{r}

# Valores originales sin NA
original <- datos$fatigue[!is.na(datos$fatigue)]

# Valores imputados por mediana
imputada_mediana <- fatigue_imputada

# Posiciones donde había NA
na_pos <- which(is.na(datos$fatigue))

# Comparar solo los valores imputados (NA reemplazados por mediana) con los originales
imputados_vs_original <- cbind(original = datos$fatigue, imputada = imputada_mediana)

# Para test t, usamos los NA reemplazados
# Aquí hacemos un t-test aproximado usando todos los valores, aunque no es estrictamente válido
t.test(original, imputada_mediana[1:length(original)], paired = TRUE)


```

El p-valor resulta muy elevado, por lo que no podemos rechazar la hipótesis nula. De esta manera, concluimos que la diferencia no es estadísticamente significativa.

A continuación, haremos una comparación de histogramas, para ver si a nivel visual hay una diferencia apreciable.

```{r}

par(mfrow = c(1, 3))  # Mostrar tres gráficos juntos

hist(datos$fatigue, main = "Original", xlab = "Fatigue", col = "lightblue")
hist(fatigue_imputada, main = "Imputación Mediana", xlab = "Fatigue", col = "lightgreen")
hist(fatigue_imputada_media, main = "Imputación Media", xlab = "Fatigue", col = "lightpink")



```

Como se puede ver, a nivel visual apenas hay diferencia. Simplemente, en ambas imputaciones,la barra que abarca los valores de la mediana incrementa (ya que la media es próxima a la mediana), pero mantienen la estructura.

Así, concluimos que apenas hay diferencias entre ambas imputaciones.

## 7. Imputación condicional en *strength_1RM*

```{r}

# Creamos una nueva variable imputada sin modificar la original
strength_1RM_imputada <- datos$strength_1RM

# Calcular media por posición y reemplazamos los NA
strength_1RM_imputada <- datos %>%
  group_by(position) %>%
  mutate(strength_1RM_imputada = ifelse(
    is.na(strength_1RM),
    mean(strength_1RM, na.rm = TRUE),
    strength_1RM
  )) %>%
  ungroup() %>%
  pull(strength_1RM_imputada)

# Comprobar que los NA fueron imputados
sum(is.na(strength_1RM_imputada))  # Debe ser 0

```

Una vez creada la variable, verificamos que cumple los objetivos y actualizaremos la variable *strength_1RM* del conjunto de datos.

```{r}

# Media por posición antes de imputar
media_original <- datos %>%
  group_by(position) %>%
  summarise(media_strength = mean(strength_1RM, na.rm = TRUE))


# Añadimos la variable al dataset
datos$strength_1RM_imputada <- strength_1RM_imputada  

# Media por posición después de imputar
media_imputada <- datos %>%
  group_by(position) %>%
  summarise(media_strength = mean(strength_1RM_imputada, na.rm = TRUE))

# Eliminamos la variable del dataset
datos$strength_1RM_imputada <- NULL


# Mostrar resultados
media_original
media_imputada

```

Vemos que los valores coinciden, por lo que la imputación ha sido realizada de forma correcta.

## 8. Comentario acerca de los valores faltantes

En primer lugar, para ello, vamos a ver el patrón de los NA. Es decir, vamos a ver dónde aparecen los NA, si hay combinaciones de NA entre variables o si aparecen de forma aleatoria.

```{r}

md.pattern(datos)

aggr(datos, prop = TRUE, numbers = TRUE)

```

Como podemos apreciar, no hay NA agrupados en la misma observación. Por tanto, podemos intuir que los valores faltantes son fruto del azar (MCAR). Por tanto, nos ayudaremos de un test estadístico que nos diga si lo son (el test mcar).

```{r}
# Visualizar proporción de NA por variable
vis_miss(datos)

# Ver patrón de NA entre variables
gg_miss_upset(datos)

mcar_test(datos)


```

Como el p-valor es mayor de 0.05, no podemos rechazar que sean MCAR.

Con esto y la información anterior, podemos concluir que los valores faltantes que tenemos son MCAR, al provenir completamente del azar.

## 9. Modelo lineal simple entre *performance_index* y *training_hours*

```{r}

# Ajustar modelo lineal simple usando solo casos completos
modelo <- lm(performance_index ~ training_hours, data = datos, na.action = na.omit)

# Resumen del modelo
summary(modelo)


```

Como tenemos un modelo con 514 grados de libertad, es fácil deducir que se han perdido 5 observaciones por NA.

A continuación, vamos a ver qué filas se han perdido exactamente.

```{r}

# Filas completas (sin NA) en performance_index y training_hours
casos_completos <- complete.cases(datos[, c("performance_index", "training_hours")])

# Filas perdidas (con NA)
filas_perdidas <- which(!casos_completos)

# Mostramos los índices de las filas perdidas
filas_perdidas


```

## 10. Modelo lineal con valores imputados

```{r}

# Ajustar modelo lineal usando la variable imputada
modelo_imputado <- lm(datos$performance_index ~ training_hours_imputada)

# Resumen del modelo
summary(modelo_imputado)


```

Vemos la diferencia entre los coeficientes de los modelos

```{r}

# Coeficientes del modelo original
coef(modelo)

# Coeficientes del modelo imputado
coef(modelo_imputado)


```

Los coeficientes han cambiado ligeramente, al cambiar el número de observaciones, con valores añadidos manualmente. Sin embargo, la diferencia es mínima, al haber muy pocos valores faltantes, por lo que los cambios no influyen prácticamente en el modelo; ya que los coeficientes cambian mínimamente.

# 3. REGRESIÓN LINEAL SIMPLE Y MÚLTIPLE

## 1. Modelo de regresión lineal simple entre *performance_index* y *training_hours*

Emplearemos las variables imputadas comentadas previamente.

```{r}

# Resumen del modelo
summary(modelo_imputado)


```

La pendiente (con valor 1.7112) indica que, por cada hora de entrenamiento, el valor del índice de rendimiento aumenta 1.7112.

## 2. Gráfico de dispersión del modelo

```{r}

# Scatterplot
plot(datos$training_hours, datos$performance_index,
     main = "Performance Index vs Training Hours",
     xlab = "Training Hours",
     ylab = "Performance Index",
     pch = 19, col = "blue")

# Añadir recta ajustada del modelo imputado
abline(lm(datos$performance_index ~ training_hours_imputada), col = "red", lwd = 2)

# Leyenda
legend("topleft", legend = c("Datos", "Recta modelo imputado"),
       col = c("blue", "red"), pch = c(19, NA), lty = c(NA, 1), lwd = c(NA, 2))


```

## 3. Cálculo y análisis del R\^2 del modelo

En primer lugar, calcularemos el R\^2 del modelo.

```{r}

# R^2 del modelo imputado
summary(modelo_imputado)$r.squared

```

El R\^2 vale 0.3279338. Esto quiere decir que el modelo explica un 32.79% de la variabilidad del índice de rendimiento.

## 4. Modelo de regresión lineal múltiple

Vamos a ajustar un modelo de regresión lineal múltiple con la variable *performance_index* explicada a partir de *training_hours*, *match_intensity* y *strength_1RM*.

```{r}

# Ajustar modelo lineal múltiple
modelo_multiple <- lm(performance_index ~ training_hours + match_intensity + strength_1RM, data = datos, na.action = na.omit)

# Resumen del modelo
summary(modelo_multiple)


```

La variable que más efecto tiene sobre el rendimiento es *training_hours*, cuyo coeficiente asociado vale 1.7253 (mucho mayor que el valor absoluto del resto).

## 5. Comparación con el modelo simple

```{r}

# Coeficiente del modelo simple
coef_simple <- coef(modelo)["training_hours"]
coef_simple

# Coeficiente del modelo múltiple
coef_multiple <- coef(modelo_multiple)["training_hours"]
coef_multiple

# Intercepto del modelo simple
intercepto_simple <- coef(modelo)["(Intercept)"]
intercepto_simple

# Intercepto del modelo múltiple
intercepto_multiple <- coef(modelo_multiple)["(Intercept)"]
intercepto_multiple

```

Vemos, de esta manera, que el coeficiente de la variable *training_hours* aumenta en el modelo múltiple y el intercepto disminuye su valor.

Esto se debe a que los coeficientes asociados a las otras variables le restan valor a las horas de entrenamientos, ajustándose así a la realidad que permite explicar el modelo. Por otro lado, tiene sentido que el intercepto sea menor, ya que la pendiente parece más pronunciada por este incremento del coeficiente asociado a la variable *training_hours*.

## 6. Adición de la variable *fatigue*

```{r}

# Ajustar modelo múltiple con fatigue
modelo_multiple2 <- lm(performance_index ~ training_hours + match_intensity + strength_1RM + fatigue, data = datos, na.action = na.omit)

# Resumen del modelo
summary(modelo_multiple2)


```

El R\^2 ajustado ha mejorado tras añadir esta nueva variable al modelo. Esto significa que es útil, ya que el hecho de haberla añadido permite explicar cierta variabilidad del índice de rendimiento.

## 7. Efecto de la variable *position*

Si metemos la variable categórica *position* en un modelo de regresión lineal múltiple con predictores cuantitativos, la variable categórica se convierte en valores Dummy de la siguiente manera:

```{r}

# Limpiar la variable
datos$position <- factor(trimws(tolower(datos$position)))

# Crear dummies
dummy_matrix <- model.matrix(~ position, data = datos)
dummy_df <- as.data.frame(dummy_matrix[, -1])

# Tabla de correspondencia: un nivel por fila
tabla_correspondencia <- unique(cbind(position = datos$position, dummy_df))
tabla_correspondencia




```

En este caso, se habrían estimado estos coeficientes Dummy para las posiciones.

El que tiene todo 0 es la referencia (en este caso, los defensas). El resto de coeficientes Dummy se comparan con este nivel.

El modelo devolverá un valor entre la diferencia de posiciones, que permite determinar la diferencia de rendimiento entre jugadores de las mismas.

## 8. Incluimos *sleep_hours* como predictor adicional

```{r}

modelo_multiple3 <- lm(performance_index ~ training_hours + match_intensity +
                         strength_1RM + fatigue + sleep_hours,
                       data = datos)
summary(modelo_multiple3)

```

Con esto, podemos ver que la fatiga influye negativamente en el rendimiento de los jugadores. De esta manera, el descanso será necesario para obtener un buen rendimiento.

## 9. Diagrama de residuos del modelo múltiple

```{r}

plot(modelo_multiple3, which = 1)


```


Los puntos aparecen dispersos aparentemente al azar en torno a la línea central. Este es un indicio de linealidad, por lo que no hay ningún motivo aparente como para descartarla. Es verdad que hay un ligero indicio de curva, pero no lo suficiente como para tomar la conclusión de descartar la linealidad.

## 10. Modelo lineal simple vs múltiple

Para este dataset, conviene más utilizar un modelo lineal simple cuando se quiere ver de forma "pura" el efecto de una sola variable para el explicar el rendimiento o cualquier otra variable. Sin embargo, si queremos explicar el por qué de una variable o de su distribución, esto no se va a deber solo a un predictor, sino que habrá que tomar varios que lo expliquen. 

De esta manera, nos conviene usar un modelo simple para ver cómo influye una variable en las demás, pero nos conviene usar un modelo múltiple para entender el comportamiento real de una variable a partir de las demás (y que se recoja mejor toda su variabilidad, atendiendo a todos sus posibles condicionantes que la alteren).

# 4. NO LINEALIDADES Y PIECEWISE

## 1. Modelo no lineal

```{r}

# Creamos el modelo lineal y el cuadrático

modelo_lineal_training <- lm(performance_index ~ training_hours, data = datos)
summary(modelo_lineal_training)

modelo_cuadratico_training <- lm(performance_index ~ training_hours + I(training_hours^2), data = datos)
summary(modelo_cuadratico_training)


```

A continuación, compararemos los modelos con ANOVA, con R^2 ajustado y con AIC

```{r}

anova(modelo_lineal_training, modelo_cuadratico_training)


```

Vemos que el p-valor del test es bastante menor que 0.05, lo cual indica que el modelo cuadrático es mejor, ya que explica mejor la varianza en el modelo.

```{r}

summary(modelo_lineal_training)$adj.r.squared
summary(modelo_cuadratico_training)$adj.r.squared


```

Vemos que el R^2 del modelo cuadrático es mayor que el del modelo lineal, por lo que hay más porcentaje de variabilidad explicada de la variable *performance_index* en el modelo cuadrátrico.

```{r}

AIC(modelo_lineal_training, modelo_cuadratico_training)

```

Vemos que en el modelo cuadrático hay un valor menor de AIC. Esto implica que será un mejor modelo, logrando un mejor ajuste que el modelo lineal sin añadir excesiva complejidad.

Con todo esto, podemos concluir que el modelo cuadrático es notablemente mejor que el modelo lineal.

## 2. Relación entre *performance_index* y *age*

En primer lugar, haremos un gráfico de dispersión para ver la relación

```{r}

plot(datos$age, datos$performance_index,
     xlab = "Edad",
     ylab = "Performance Index",
     main = "Relación entre Performance y Edad",
     pch = 19, col = "blue")


```

Esto nos permite intuir que el índice de rendimiento parece ser mayor conforme la edad aumenta. Sin embargo, para verificarlo y detectar formas cuadráticas, haremos un modelo cuadrático.

```{r}

modelo_age <- lm(performance_index ~ age + I(age^2), data = datos)
summary(modelo_age)


```
Efectivamente, tal y como intuíamos, el índice de rendimiento incrementa conforme la edad aumenta.

Además, vemos que *age^2* es negativo en el modelo. Con esto, sabemos que obtendremos un pico en el modelo. Para verlo mejor, añadiremos al gráfico anterior la curva del modelo cuadrático.

```{r}

plot(datos$age, datos$performance_index,
     xlab = "Edad",
     ylab = "Performance Index",
     main = "Relación entre Performance y Edad",
     pch = 19, col = "blue")

age_seq <- seq(min(datos$age), max(datos$age), length.out = 100)
pred <- predict(modelo_age, newdata = data.frame(age = age_seq))

lines(age_seq, pred, col = "red", lwd = 2)


```

Así, la relación es cuadrática, aunque parece tener una tendencia suave; no muy pronunciada. Vamos a calcular el valor del pico y lo añadiremos a la gráfica anterior.

```{r}

beta <- coef(modelo_age)
age_pico <- -beta["age"] / (2 * beta["I(age^2)"])
age_pico


```
Así, el pico de rendimiento se da a los 31.80029 años. A partir de entonces, el rendimiento empieza a bajar. A continuación aparece el gráfico completo con el pico marcado.

```{r}

# Gráfico de dispersión
plot(datos$age, datos$performance_index,
     xlab = "Edad",
     ylab = "Performance Index",
     main = "Rendimiento vs Edad con Curva Cuadrática",
     pch = 19, col = "blue")

# Agregar la curva cuadrática ajustada
lines(age_seq, pred, col = "red", lwd = 2)

# Marcar el pico en el gráfico
points(age_pico, performance_pico, col = "black", pch = 19, cex = 1.5)
text(age_pico, performance_pico, 
     labels = paste0(round(age_pico, 1), " años"), 
     pos = 3, col = "black")


```

## 3. Variable dicotómica para *sleep_hours*

```{r}

# Creamos sleep_group: 0 = <6h, 1 = ≥6h
datos$sleep_group <- ifelse(datos$sleep_hours < 6, 0, 1)

# Convertir a factor para que R lo trate como categoría
datos$sleep_group <- factor(datos$sleep_group, labels = c("<6h", "≥6h"))


```

Una vez creada la variable, la ajustaremos como predictora del modelo

```{r}

modelo_sueño <- lm(performance_index ~ sleep_group, data = datos)
summary(modelo_sueño)

```
Analizando la salida, vemos que los jugadores que han dormido más de 6 horas incrementan su rendimiento. El intercepto indica la media de rendimiento de jugadores con menos de 6 horas de sueño, mientras que el otro coeficiente (2.436) indica la diferencia entre los jugadores que han dormido más de 6 horas con respecto de aquellos que no. De esta manera, un mayor descanso deriva en un mejor rendimiento.

Por último, vamos a plantear un boxplot para visualizar mejor esta diferencia.

```{r}

boxplot(performance_index ~ sleep_group, data = datos,
        xlab = "Horas de sueño",
        ylab = "Performance Index",
        main = "Rendimiento según horas de sueño",
        col = c("lightblue", "lightgreen"))


```

## 4. *performance_index* frente a *fatigue* empleando un LOESS

```{r}

library(ggplot2)

ggplot(datos, aes(x = fatigue, y = performance_index)) +
  geom_point(color = "blue") +
  geom_smooth(method = "loess", color = "red", se = TRUE) +
  labs(title = "Rendimiento vs Fatigue con LOESS",
       x = "Fatigue",
       y = "Performance Index") +
  theme_minimal()


```


Podemos ver en la gráfica que la relación planteada es no lineal, con dos pequeños "picos" y un "valle" entre medias, y una posterior caída. 

## 5. Spline sobre *training_hours* y comparación con método cuadrático

```{r}


# Ajustamos un spline cúbico con 4 knots por defecto
modelo_spline <- lm(performance_index ~ bs(training_hours, df = 4), data = datos)
summary(modelo_spline)


```
A continuación, graficaremos ambos modelos para ver la diferencia

```{r}

library(ggplot2)

ggplot(datos, aes(x = training_hours, y = performance_index)) +
  geom_point(color = "blue", alpha = 0.6) +  # puntos de datos
  stat_smooth(aes(color = "Cuadrático"), method = "lm", formula = y ~ poly(x, 2), se = FALSE, linetype = "dashed", size = 1) +
  stat_smooth(aes(color = "Spline"), method = "lm", formula = y ~ bs(x, 4), se = FALSE, size = 1) +
  scale_color_manual(name = "Modelo", values = c("Cuadrático" = "red", "Spline" = "darkgreen")) +
  labs(title = "Comparación: Modelo cuadrático vs Spline",
       x = "Training Hours", y = "Performance Index") +
  theme_minimal()


```


Vemos que el spline recoge mejor la no linealidad de la relación, ajustándose mejor a los valores reales. 

Por otro lado, vamos a comparar formalmente ambos ajustes.


```{r}

# AIC
AIC(modelo_cuadratico_training, modelo_spline)

# R² ajustado
summary(modelo_cuadratico_training)$adj.r.squared
summary(modelo_spline)$adj.r.squared


```

Vemos que el AIC del modelo cuadrático es algo mayor, por lo que se ajusta un poco mejor a la relación. Sin embargo, el R^2 del modelo spline es mayor, explicando más variabilidad.

La conclusión que podemos sacar es que ambos modelos son muy similares, explicando una variabilidad parecida. De esta manera, no parece que uno sea mucho mejor que el otro.


## 6. Piecewise en travel_km_week

En primer lugar, vamos a crear la variable dicotómica *travel_group*.

```{r}

datos$travel_group <- ifelse(datos$travel_km_week <= 1500, "≤1500", ">1500")

datos$travel_group <- factor(datos$travel_group, levels = c("≤1500", ">1500"))


```

A continuación, ajustaremos el modelo lineal con esta variable.

```{r}

modelo_piecewise <- lm(performance_index ~ travel_group, data = datos)
summary(modelo_piecewise)

```

Con la salida del modelo, vemos que el índice de rendimiento disminuye para aquellos jugadores que han viajado más de 1500 km a la semana. Esto se puede comprobar ya que el coeficiente asociado a esta variable es negativo (-5.9998). El valor de este coeficiente será la diferencia con los jugadores pertenecientes al otro grupo.

Finalmente, dispondremos un boxplot para ver la diferencia de manera visual.

```{r}

boxplot(performance_index ~ travel_group, data = datos,
        xlab = "Distancia semanal de viaje",
        ylab = "Performance Index",
        main = "Rendimiento según travel_km_week",
        col = c("lightblue", "lightgreen"))


```

## 7. Evaluación del AIC entre modelos lineal, cuadrático y piecewise para *training_hours*

Tenemos el modelo lineal y el cuadrático creados en anteriores apartados. Nos falta, por tanto, crear el modelo piecewise.

Para ello, en primer lugar crearemos la variable dicotómica *training_group*.

```{r}

datos$training_group <- ifelse(datos$training_hours <= 20, "≤20", ">20")
datos$training_group <- factor(datos$training_group, levels = c("≤20", ">20"))


```

Con esta, creamos el modelo piecewise

```{r}

modelo_piecewise_training <- lm(performance_index ~ training_group, data = datos)

```


Ahora, podremos comparar el AIC de estos modelos

```{r}

AIC(modelo_lineal_training, modelo_cuadratico_training, modelo_piecewise_training)

```

El modelo piecewise es el de mayor AIC, mientras que el cuadrático es el de menor AIC. De esta manera, el mejor modelo será el cuadrático, ya que es el que mejor combina ajuste y simplicidad.



