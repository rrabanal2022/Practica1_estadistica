---
title: "Práctica 1 estadística"
author: "Ramón Martínez, Rodrigo Rabanal"
format:
  html:
    theme: minty
    css: estilos.css
execute:
  echo: false
  warning: false
editor: visual
toc: true
toc-location: left
toc-depth: 2
---

<img src="logo.png" class="logo"/>

# 1. EXPLORACIÓN INICIAL

Antes de empezar, cargamos las librerías que vamos a usar.

```{r message=FALSE, warning=FALSE}

library(dplyr)
library(mice)
library(VIM)
library(naniar)
library(car)
library(splines)
library(lmtest)
library(sandwich)
library(ggplot2)
library(MASS)
library(pROC)
library(DescTools)

```

Empezaremos planteando una visualización de los datos, para entender la naturaleza de las variables y ver los valores con los que trabajaremos.

```{r}
datos <- read.csv("athletics_B.csv")

summary(datos)

str(datos)
```

Vamos a realizar un pequeño análisis exploratorio de datos, atendiendo a diferentes aspectos de los mismos.

## 1. Media, mediana y desviación típica

En primer lugar, calcularemos la media, la mediana y la desviación típica del índice de rendimiento de los jugadores.

```{r}
#Calculamos la media del índice de rendimiento de los jugadores

media_performance <- mean(datos$performance_index, na.rm = TRUE)

#Devolvemos el valor calculado

media_performance

#Calculamos la mediana del índice de rendimiento de los jugadores

mediana_performance <- median(datos$performance_index, na.rm = TRUE)

#Devolvemos el valor calculado

mediana_performance

#Calculamos la desviación típica del índice de rendimiento de los jugadores

dtip_performance <- sd(datos$performance_index, na.rm = TRUE)

#Devolvemos el valor calculado

dtip_performance

```

Se aprecia una media y una mediana parecidas, lo que parece indicar que la mayoría de jugadores se encuentran en un estado de forma relativamente similar.

## 2. Histograma de la variable *performance_index*

```{r}
#Vamos a hacer un histograma del índice de rendimiento de los jugadores en 20 intervalos

# Histograma de performance_index con 20 intervalos
hist(datos$performance_index,
     breaks = 20,            
     main = "Histograma de Performance Index",  
     xlab = "Performance Index",                
     ylab = "Frecuencia",                       
     col = "skyblue",                           
     border = "white",
     freq = FALSE) 

lines(density(datos$performance_index),
      col = "red",
      lwd = 2)  

cuartiles <- quantile(datos$performance_index, probs = c(0.25, 0.5, 0.75))

# Añadimos líneas verticales discontinuas en los cuartiles
abline(v = cuartiles, 
       col = "darkgreen", 
       lty = 2,      # tipo de línea discontinua
       lwd = 2)      # grosor


```

En el histograma, podemos apreciar que la variable *performance_index* sigue una distribución normal.

La línea roja marca la distribución, mientras que las líneas verdes discontinuas marcan los valores de los cuartiles; entre los que se encuentra el 50% de la muestra para esta variable.

Esto complementa a lo que hemos deducido previamente a partir de los datos de la media y la mediana.

## 3. Distribución de frecuencias relativas

```{r}
#Vamos a calcular la distribución de las frecuencias relativas de los jugadores por posición

frecuencia <- table(datos$position)

frecuencia_relativa <- prop.table(frecuencia)

# Mostrar la tabla con frecuencias absolutas y relativas (en porcentaje)
tabla_frecuencias <- data.frame(
  Posición = names(frecuencia),
  Frecuencia = as.vector(frecuencia),
  Frecuencia_Relativa = round(as.vector(frecuencia_relativa) * 100, 2)
)

# Mostrar resultados
tabla_frecuencias

```

Podemos observar que la frecuencia relativa de porteros es mucho menor que la del resto de posiciones. Esto se debe a que en un equipo juega un solo portero para los 3 o 4 defensas, 3 o 4 mediocentros y 2 o 3 delanteros. Por tanto, es lógico obtener ese valor. Caso análogo, pero en menor medida para los delanteros, que suponen un número inferior en la plantilla que los mediocentros y los defensas.

## 4. Diagrama de cajas de *performace_index* según el equipo

```{r}

# Diagrama de cajas de performance_index según team
boxplot(performance_index ~ team, 
        data = datos,
        main = "Diagrama de Cajas de Performance Index por Equipo",
        xlab = "Equipo",
        ylab = "Performance Index",
        col = c("lightblue", "lightgreen", "lightpink", "khaki"),
        border = "darkgray",
        notch = TRUE)

```

En este *boxplot* podemos ver que en el equipo B hay una mayor variabilidad de resultados, pues los cuartiles son más grandes que los de los equipos A y B (que tienen niveles más similares de rendimiento). Sin embargo, la mediana del equipo B es claramente mayor que la del resto de equipos.

Esto puede indicar un mayor nivel de algunos jugadores del equipo B con respecto de los jugadores del resto de equipos, pero también entre los jugadores del mismo equipo (mucha diferencia entre jugadores "estrellas" y el resto).

Por último, en el equipo C tienen todos los jugadores un nivel muy similar; lo que podría provocar que el rendimiento medio sea mayor.

## 5. Gráfico de dispersión entre *training_hours* y *performance_index*

```{r}
#Construimos un gráfico de dispersión entre training_hours y performance_index
plot(datos$training_hours, datos$performance_index,
     main = "Relación entre horas de entrenamiento y rendimiento",
     xlab = "Horas de entrenamiento (training_hours)",
     ylab = "Índice de rendimiento (performance_index)",
     pch = 19,               # tipo de punto sólido
     col = "steelblue",      # color de los puntos
     cex = 1.2)              # tamaño de los puntos

# Agregar una línea de tendencia (regresión lineal)
abline(lm(performance_index ~ training_hours, data = datos), 
       col = "red", lwd = 2)
```

Se aprecia linealidad en el modelo. Hay una clara relación lineal entre las horas de entrenamiento y el índice de rendimiento, apreciando un mayor rendimiento conforme aumentan las horas de entrenamiento.

## 6. Matriz de correlaciones

```{r}
#Calculamos la matriz de correlaciones entre variables numéricas
datos_numericos <- datos[, sapply(datos, is.numeric)]

# Calcular la matriz de correlaciones
matriz_cor <- cor(datos_numericos, use = "complete.obs")

# Mostrar la matriz de correlaciones
matriz_cor

#Vamos a visualizarla
library(corrplot)

corrplot(matriz_cor, method = "color", type = "upper",
         tl.col = "black", tl.cex = 0.8, 
         addCoef.col = "black", number.cex = 0.4)

```

Aquí podemos ver la matriz de correlaciones. Vemos que las variables que presentan más correlación son los pases realizados con éxito y los pases intentados. Otras variables que presentan cierta correlación son el índice de rendimiento con la edad y las horas de entrenamiento.

## 7. Gráfico de dispersión entre fatiga e índice de rendimiento

```{r}

#Representamos un gráfico de dispersión entre training_hours y performance_index
library(ggplot2)

ggplot(datos, aes(x = fatigue, y = performance_index)) +
  geom_point(color = "steelblue", size = 2) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(title = "Relación entre fatiga e índice de rendimiento",
       x = "Fatiga",
       y = "Índice de rendimiento") +
  theme_minimal()

```

Parece que hay una relación lineal entre ambas variables. En particular, podemos observar que parece haber una relación que indica una menor índice de rendimiento conforme la fatiga incrementa.

## 8. Boxplot del índice de rendimiento por posición

```{r}
#Realizamos un boxplot de performance_index por posicion

boxplot(performance_index ~ position,
        data = datos,
        main = "Diagrama de Cajas de Performance Index por Posición",
        xlab = "Posición",
        ylab = "Performance Index",
        col = c("lightblue", "lightgreen", "lightpink", "khaki"),
        border = "gray40",
        notch = TRUE)


```

Se aprecian una serie de diferencias entre puestos, que procederemos a desarrollar. En primer lugar, no hay grandes diferencias en lo referente a la media del índice de rendimiento en función de la posición. Por otro lado, vemos que el tercer cuartil de los defensas es más pequeño que el resto, dando a entender que se encuentran más agrupados en esas zonas de rendimiento; destacando menos que en otras posiciones. Además, hay tres outliers con valores muy bajos de rendimiento. Finalmente, el último valor remarcable es el del portero, donde vemos que el "bigote" es de longitud mucho menor que el del resto de posiciones.

## 9. Valores atípicos en *agility_time*

```{r}
# Vamos a identificar los valores atípicos en agility_time 

# Calculamos los cuartiles y el rango intercuartílico
Q1 <- quantile(datos$agility_time, 0.25, na.rm = TRUE)
Q3 <- quantile(datos$agility_time, 0.75, na.rm = TRUE)
IQR_value <- IQR(datos$agility_time, na.rm = TRUE)

# Límites inferior y superior para detectar atípicos
lim_inf <- Q1 - 1.5 * IQR_value
lim_sup <- Q3 + 1.5 * IQR_value

# Identificamos los valores atípicos
outliers <- datos$agility_time[datos$agility_time < lim_inf | datos$agility_time > lim_sup]

# Mostramos resultados
outliers

```

Vemos que por la regla del rango intercuartílico (IQR) hay 5 valores atípicos, que se corresponden con NA. Es decir, valores no recogidos de esta variable para ciertos jugadores. Vamos a hacer un boxplot para intentar ver más posibles valores atípicos, donde estos hayan sido recogidos.

```{r}
boxplot(datos$agility_time,
        main = "Detección de valores atípicos en Agility Time",
        ylab = "Agility Time",
        col = "lightblue",
        border = "gray40")

```

La conclusión del boxplot es la misma. No hay valores atípicos en la variable agility_time, más allá de los valores no recogidos.

## 10. Proporción de jugadores zurdos en la base de datos

```{r}

# Calculamos la proporción de jugadores zurdos
proporcion_zurdos <- mean(datos$left_footed == 1, na.rm = TRUE)

# Mostramos el resultado en porcentaje
proporcion_zurdos * 100


```

Como podemos ver, el 29,17% de los jugadores de la base de datos son zurdos.

# 2. MANEJO DE VALORES FALTANTES

## 1. Identificación de variables con valores faltantes

Primero, vemos qué columnas tienen valores NA

```{r}

# Ver columnas que contienen al menos un NA
colnames(datos)[colSums(is.na(datos)) > 0]


```

Las variables *training_hours*, *sleep_hours*, *fatigue*, *strength_1RM* y *agility_time* tienen valores faltantes.

Ahora, veremos cuántos valores faltan en cada una

```{r}
# Cantidad de NA solo en columnas donde hay al menos uno
na_counts <- colSums(is.na(datos))
na_counts[na_counts > 0]


```

Así, vemos que hay 5 valores faltantes en cada una de estas variables.

## 2. Calculamos la proporción de valores faltantes sobre el dataset completo

```{r}

# Porcentaje total de NA
mean(is.na(datos)) * 100


```

Es decir, el 0.25% de los valores del dataset son valores faltantes.

## 3. Resumen de combina las variables con missing y su porcentaje de valores ausentes

```{r}

# Calcular cantidad y porcentaje de NA por variable
na_table <- data.frame(
  variable = colnames(datos),
  na_count = colSums(is.na(datos)),
  na_percent = (1- colMeans(is.na(datos)) * 100)
)

# Filtrar solo variables con al menos un NA
na_table <- na_table[na_table$na_count > 0, ]

# Mostrar tabla
na_table


```

## 4. Imputación por la media en *training_hours*

```{r}

# Calculamos la media de training_hours ignorando NA
media_training <- mean(datos$training_hours, na.rm = TRUE)

# Imputamos los NA con la media
training_hours_imputada <- datos$training_hours
training_hours_imputada[is.na(training_hours_imputada)] <- media_training

# Calculamos de nuevo la media después de imputar
nueva_media_training <- mean(training_hours_imputada)

# Comprobamos que el valor es el mismo
media_training
nueva_media_training


```

Con esto, hemos sustituido los valores faltantes de la variable *training_hours* con la media de los valores de esta variable.

## 5. Histogramas de *sleep_hours* antes y después de la imputación por la media

En primer lugar, trabajaremos con la variable sin imputar (con valores faltantes).

```{r}

# Guardamos una copia de la variable original
sleep_original <- datos$sleep_hours

# Calculamos la media sin NA
media_sleep <- mean(datos$sleep_hours, na.rm = TRUE)

```

A continuación, trabajaremos con la versión imputada.

```{r}

# Creamos la versión imputada
sleep_imputada <- datos$sleep_hours
sleep_imputada[is.na(sleep_imputada)] <- media_sleep

```

Ahora, podemos desarrollar los histogramas.

```{r}

# Histogramas antes y después
par(mfrow = c(1, 2))  # Mostrar dos gráficos juntos

hist(sleep_original,
     main = "Sleep Hours - Antes imputación",
     xlab = "Horas de sueño")

hist(sleep_imputada,
     main = "Sleep Hours - Después imputación con media",
     xlab = "Horas de sueño")


```

Como podemos ver, no se aprecian diferencias aparentes. Esto se debe al hecho de que, al imputar los valores faltantes por la media, no modificamos la estructura presente de la variable. Así, el único cambio aparente es un aumento de la frecuencia para los valores cercanos a la mediana (asumimos que son los imputados). Sin embargo, como afirmamos, la distribución es la misma.

## 6. Imputación por la mediana en *fatigue* y comparación con imputación con la media.

En primer lugar, imputamos los valores por la mediana en la variable *fatigue*.

```{r}
# Calculamos la mediana ignorando NA
mediana_fatigue <- median(datos$fatigue, na.rm = TRUE)

# Crear una nueva variable con la imputación
fatigue_imputada <- datos$fatigue
fatigue_imputada[is.na(fatigue_imputada)] <- mediana_fatigue

# Comprobamos que ya no hay NA
sum(is.na(fatigue_imputada))


```

A continuación, hacemos la imputación por la media.

```{r}

# Calcular la media ignorando NA
media_fatigue <- mean(datos$fatigue, na.rm = TRUE)

# Crear nueva variable imputada por la media
fatigue_imputada_media <- datos$fatigue
fatigue_imputada_media[is.na(fatigue_imputada_media)] <- media_fatigue

# Comprobar la imputación
sum(is.na(fatigue_imputada_media))  


```

Ahora, porcedemos a comparar estas nuevas variables creadas.

Para ello, empezaremos comparando estadísticas básicas mediante una tabla

```{r}

# Media original (ignorando NA)
media_original <- mean(datos$fatigue, na.rm = TRUE)

# Media tras imputación por mediana
media_median <- mean(fatigue_imputada, na.rm = TRUE)

# Media tras imputación por media
media_mean <- mean(fatigue_imputada_media, na.rm = TRUE)

# Mediana original
mediana_original <- median(datos$fatigue, na.rm = TRUE)

# Mediana tras imputación por mediana
mediana_median <- median(fatigue_imputada, na.rm = TRUE)

# Mediana tras imputación por media
mediana_mean <- median(fatigue_imputada_media, na.rm = TRUE)

data.frame(
  Version = c("Original", "Imputación Mediana", "Imputación Media"),
  Media = c(media_original, media_median, media_mean),
  Mediana = c(mediana_original, mediana_median, mediana_mean)
)


```

De esta manera, vemos que la imputación por la mediana modifica ligeramente la media de la variable; mientras que el valor de la mediana permanece intacto en cualquier caso.

Vamos a ver si este cambio es significativo. Para ello, haremos un *t-test*, cuya hipótesis nula será que el cambio no es significativo.

```{r}

# Valores originales sin NA
original <- datos$fatigue[!is.na(datos$fatigue)]

# Valores imputados por mediana
imputada_mediana <- fatigue_imputada

# Posiciones donde había NA
na_pos <- which(is.na(datos$fatigue))

# Comparar solo los valores imputados (NA reemplazados por mediana) con los originales
imputados_vs_original <- cbind(original = datos$fatigue, imputada = imputada_mediana)

# Para test t, usamos los NA reemplazados
# Aquí hacemos un t-test aproximado usando todos los valores, aunque no es estrictamente válido
t.test(original, imputada_mediana[1:length(original)], paired = TRUE)


```

El p-valor resulta muy elevado, por lo que no podemos rechazar la hipótesis nula. De esta manera, concluimos que la diferencia no es estadísticamente significativa.

A continuación, haremos una comparación de histogramas, para ver si a nivel visual hay una diferencia apreciable.

```{r}

par(mfrow = c(1, 3))  # Mostrar tres gráficos juntos

hist(datos$fatigue, main = "Original", xlab = "Fatigue", col = "lightblue")
hist(fatigue_imputada, main = "Imputación Mediana", xlab = "Fatigue", col = "lightgreen")
hist(fatigue_imputada_media, main = "Imputación Media", xlab = "Fatigue", col = "lightpink")



```

Como se puede ver, a nivel visual apenas hay diferencia. Simplemente, en ambas imputaciones,la barra que abarca los valores de la mediana incrementa (ya que la media es próxima a la mediana), pero mantienen la estructura.

Así, concluimos que apenas hay diferencias entre ambas imputaciones.

## 7. Imputación condicional en *strength_1RM*

```{r}

# Creamos una nueva variable imputada sin modificar la original
strength_1RM_imputada <- datos$strength_1RM

# Calcular media por posición y reemplazamos los NA
strength_1RM_imputada <- datos %>%
  group_by(position) %>%
  mutate(strength_1RM_imputada = ifelse(
    is.na(strength_1RM),
    mean(strength_1RM, na.rm = TRUE),
    strength_1RM
  )) %>%
  ungroup() %>%
  pull(strength_1RM_imputada)

# Comprobar que los NA fueron imputados
sum(is.na(strength_1RM_imputada))  # Debe ser 0

```

Una vez creada la variable, verificamos que cumple los objetivos y actualizaremos la variable *strength_1RM* del conjunto de datos.

```{r}

# Media por posición antes de imputar
media_original <- datos %>%
  group_by(position) %>%
  summarise(media_strength = mean(strength_1RM, na.rm = TRUE))


# Añadimos la variable al dataset
datos$strength_1RM_imputada <- strength_1RM_imputada  

# Media por posición después de imputar
media_imputada <- datos %>%
  group_by(position) %>%
  summarise(media_strength = mean(strength_1RM_imputada, na.rm = TRUE))

# Eliminamos la variable del dataset
datos$strength_1RM_imputada <- NULL


# Mostrar resultados
media_original
media_imputada

```

Vemos que los valores coinciden, por lo que la imputación ha sido realizada de forma correcta.

## 8. Comentario acerca de los valores faltantes

En primer lugar, para ello, vamos a ver el patrón de los NA. Es decir, vamos a ver dónde aparecen los NA, si hay combinaciones de NA entre variables o si aparecen de forma aleatoria.

```{r}

md.pattern(datos)

aggr(datos, prop = TRUE, numbers = TRUE)

```

Como podemos apreciar, no hay NA agrupados en la misma observación. Por tanto, podemos intuir que los valores faltantes son fruto del azar (MCAR). Por tanto, nos ayudaremos de un test estadístico que nos diga si lo son (el test mcar).

```{r}
# Visualizar proporción de NA por variable
vis_miss(datos)

# Ver patrón de NA entre variables
gg_miss_upset(datos)

mcar_test(datos)


```

Como el p-valor es mayor de 0.05, no podemos rechazar que sean MCAR.

Con esto y la información anterior, podemos concluir que los valores faltantes que tenemos son MCAR, al provenir completamente del azar.

## 9. Modelo lineal simple entre *performance_index* y *training_hours*

```{r}

# Ajustar modelo lineal simple usando solo casos completos
modelo <- lm(performance_index ~ training_hours, data = datos, na.action = na.omit)

# Resumen del modelo
summary(modelo)


```

Como tenemos un modelo con 514 grados de libertad, es fácil deducir que se han perdido 5 observaciones por NA.

A continuación, vamos a ver qué filas se han perdido exactamente.

```{r}

# Filas completas (sin NA) en performance_index y training_hours
casos_completos <- complete.cases(datos[, c("performance_index", "training_hours")])

# Filas perdidas (con NA)
filas_perdidas <- which(!casos_completos)

# Mostramos los índices de las filas perdidas
filas_perdidas


```

## 10. Modelo lineal con valores imputados

```{r}

# Ajustar modelo lineal usando la variable imputada
modelo_imputado <- lm(datos$performance_index ~ training_hours_imputada)

# Resumen del modelo
summary(modelo_imputado)


```

Vemos la diferencia entre los coeficientes de los modelos

```{r}

# Coeficientes del modelo original
coef(modelo)

# Coeficientes del modelo imputado
coef(modelo_imputado)


```

Los coeficientes han cambiado ligeramente, al cambiar el número de observaciones, con valores añadidos manualmente. Sin embargo, la diferencia es mínima, al haber muy pocos valores faltantes, por lo que los cambios no influyen prácticamente en el modelo; ya que los coeficientes cambian mínimamente.

# 3. REGRESIÓN LINEAL SIMPLE Y MÚLTIPLE

## 1. Modelo de regresión lineal simple entre *performance_index* y *training_hours*

Emplearemos las variables imputadas comentadas previamente.

```{r}

# Resumen del modelo
summary(modelo_imputado)


```

La pendiente (con valor 1.7112) indica que, por cada hora de entrenamiento, el valor del índice de rendimiento aumenta 1.7112.

## 2. Gráfico de dispersión del modelo

```{r}

# Scatterplot
plot(datos$training_hours, datos$performance_index,
     main = "Performance Index vs Training Hours",
     xlab = "Training Hours",
     ylab = "Performance Index",
     pch = 19, col = "blue")

# Añadir recta ajustada del modelo imputado
abline(lm(datos$performance_index ~ training_hours_imputada), col = "red", lwd = 2)

# Leyenda
legend("topleft", legend = c("Datos", "Recta modelo imputado"),
       col = c("blue", "red"), pch = c(19, NA), lty = c(NA, 1), lwd = c(NA, 2))


```

## 3. Cálculo y análisis del R\^2 del modelo

En primer lugar, calcularemos el R\^2 del modelo.

```{r}

# R^2 del modelo imputado
summary(modelo_imputado)$r.squared

```

El R\^2 vale 0.3279338. Esto quiere decir que el modelo explica un 32.79% de la variabilidad del índice de rendimiento.

## 4. Modelo de regresión lineal múltiple

Vamos a ajustar un modelo de regresión lineal múltiple con la variable *performance_index* explicada a partir de *training_hours*, *match_intensity* y *strength_1RM*.

```{r}

# Ajustar modelo lineal múltiple
modelo_multiple <- lm(performance_index ~ training_hours + match_intensity + strength_1RM, data = datos, na.action = na.omit)

# Resumen del modelo
summary(modelo_multiple)


```

La variable que más efecto tiene sobre el rendimiento es *training_hours*, cuyo coeficiente asociado vale 1.7253 (mucho mayor que el valor absoluto del resto).

## 5. Comparación con el modelo simple

```{r}

# Coeficiente del modelo simple
coef_simple <- coef(modelo)["training_hours"]
coef_simple

# Coeficiente del modelo múltiple
coef_multiple <- coef(modelo_multiple)["training_hours"]
coef_multiple

# Intercepto del modelo simple
intercepto_simple <- coef(modelo)["(Intercept)"]
intercepto_simple

# Intercepto del modelo múltiple
intercepto_multiple <- coef(modelo_multiple)["(Intercept)"]
intercepto_multiple

```

Vemos, de esta manera, que el coeficiente de la variable *training_hours* aumenta en el modelo múltiple y el intercepto disminuye su valor.

Esto se debe a que los coeficientes asociados a las otras variables le restan valor a las horas de entrenamientos, ajustándose así a la realidad que permite explicar el modelo. Por otro lado, tiene sentido que el intercepto sea menor, ya que la pendiente parece más pronunciada por este incremento del coeficiente asociado a la variable *training_hours*.

## 6. Adición de la variable *fatigue*

```{r}

# Ajustar modelo múltiple con fatigue
modelo_multiple2 <- lm(performance_index ~ training_hours + match_intensity + strength_1RM + fatigue, data = datos, na.action = na.omit)

# Resumen del modelo
summary(modelo_multiple2)


```

El R\^2 ajustado ha mejorado tras añadir esta nueva variable al modelo. Esto significa que es útil, ya que el hecho de haberla añadido permite explicar cierta variabilidad del índice de rendimiento.

## 7. Efecto de la variable *position*

Si metemos la variable categórica *position* en un modelo de regresión lineal múltiple con predictores cuantitativos, la variable categórica se convierte en valores Dummy de la siguiente manera:

```{r}

# Limpiar la variable
datos$position <- factor(trimws(tolower(datos$position)))

# Crear dummies
dummy_matrix <- model.matrix(~ position, data = datos)
dummy_df <- as.data.frame(dummy_matrix[, -1])

# Tabla de correspondencia: un nivel por fila
tabla_correspondencia <- unique(cbind(position = datos$position, dummy_df))
tabla_correspondencia




```

En este caso, se habrían estimado estos coeficientes Dummy para las posiciones.

El que tiene todo 0 es la referencia (en este caso, los defensas). El resto de coeficientes Dummy se comparan con este nivel.

El modelo devolverá un valor entre la diferencia de posiciones, que permite determinar la diferencia de rendimiento entre jugadores de las mismas.

## 8. Incluimos *sleep_hours* como predictor adicional

```{r}

modelo_multiple3 <- lm(performance_index ~ training_hours + match_intensity +
                         strength_1RM + fatigue + sleep_hours,
                       data = datos)
summary(modelo_multiple3)

```

Con esto, podemos ver que la fatiga influye negativamente en el rendimiento de los jugadores. De esta manera, el descanso será necesario para obtener un buen rendimiento.

## 9. Diagrama de residuos del modelo múltiple

```{r}

plot(modelo_multiple3, which = 1)


```

Los puntos aparecen dispersos aparentemente al azar en torno a la línea central. Este es un indicio de linealidad, por lo que no hay ningún motivo aparente como para descartarla. Es verdad que hay un ligero indicio de curva, pero no lo suficiente como para tomar la conclusión de descartar la linealidad.

## 10. Modelo lineal simple vs múltiple

Para este dataset, conviene más utilizar un modelo lineal simple cuando se quiere ver de forma "pura" el efecto de una sola variable para el explicar el rendimiento o cualquier otra variable. Sin embargo, si queremos explicar el por qué de una variable o de su distribución, esto no se va a deber solo a un predictor, sino que habrá que tomar varios que lo expliquen.

De esta manera, nos conviene usar un modelo simple para ver cómo influye una variable en las demás, pero nos conviene usar un modelo múltiple para entender el comportamiento real de una variable a partir de las demás (y que se recoja mejor toda su variabilidad, atendiendo a todos sus posibles condicionantes que la alteren).

# 4. NO LINEALIDADES Y PIECEWISE

## 1. Modelo no lineal

```{r}

# Creamos el modelo lineal y el cuadrático

modelo_lineal_training <- lm(performance_index ~ training_hours, data = datos)
summary(modelo_lineal_training)

modelo_cuadratico_training <- lm(performance_index ~ training_hours + I(training_hours^2), data = datos)
summary(modelo_cuadratico_training)


```

A continuación, compararemos los modelos con ANOVA, con R\^2 ajustado y con AIC

```{r}

anova(modelo_lineal_training, modelo_cuadratico_training)


```

Vemos que el p-valor del test es bastante menor que 0.05, lo cual indica que el modelo cuadrático es mejor, ya que explica mejor la varianza en el modelo.

```{r}

summary(modelo_lineal_training)$adj.r.squared
summary(modelo_cuadratico_training)$adj.r.squared


```

Vemos que el R\^2 del modelo cuadrático es mayor que el del modelo lineal, por lo que hay más porcentaje de variabilidad explicada de la variable *performance_index* en el modelo cuadrátrico.

```{r}

AIC(modelo_lineal_training, modelo_cuadratico_training)

```

Vemos que en el modelo cuadrático hay un valor menor de AIC. Esto implica que será un mejor modelo, logrando un mejor ajuste que el modelo lineal sin añadir excesiva complejidad.

Con todo esto, podemos concluir que el modelo cuadrático es notablemente mejor que el modelo lineal.

## 2. Relación entre *performance_index* y *age*

En primer lugar, haremos un gráfico de dispersión para ver la relación

```{r}

plot(datos$age, datos$performance_index,
     xlab = "Edad",
     ylab = "Performance Index",
     main = "Relación entre Performance y Edad",
     pch = 19, col = "blue")


```

Esto nos permite intuir que el índice de rendimiento parece ser mayor conforme la edad aumenta. Sin embargo, para verificarlo y detectar formas cuadráticas, haremos un modelo cuadrático.

```{r}

modelo_age <- lm(performance_index ~ age + I(age^2), data = datos)
summary(modelo_age)


```

Efectivamente, tal y como intuíamos, el índice de rendimiento incrementa conforme la edad aumenta.

Además, vemos que *age\^2* es negativo en el modelo. Con esto, sabemos que obtendremos un pico en el modelo. Para verlo mejor, añadiremos al gráfico anterior la curva del modelo cuadrático.

```{r}

plot(datos$age, datos$performance_index,
     xlab = "Edad",
     ylab = "Performance Index",
     main = "Relación entre Performance y Edad",
     pch = 19, col = "blue")

age_seq <- seq(min(datos$age), max(datos$age), length.out = 100)
pred <- predict(modelo_age, newdata = data.frame(age = age_seq))

lines(age_seq, pred, col = "red", lwd = 2)


```

Así, la relación es cuadrática, aunque parece tener una tendencia suave; no muy pronunciada. Vamos a calcular el valor del pico y lo añadiremos a la gráfica anterior.

```{r}

beta <- coef(modelo_age)
age_pico <- -beta["age"] / (2 * beta["I(age^2)"])
age_pico
performance_pico <- predict(modelo_age, newdata = data.frame(age = age_pico))


```

Así, el pico de rendimiento se da a los 31.80029 años. A partir de entonces, el rendimiento empieza a bajar. A continuación aparece el gráfico completo con el pico marcado.

```{r}

# Gráfico de dispersión
plot(datos$age, datos$performance_index,
     xlab = "Edad",
     ylab = "Performance Index",
     main = "Rendimiento vs Edad con Curva Cuadrática",
     pch = 19, col = "blue")

# Agregar la curva cuadrática ajustada
lines(age_seq, pred, col = "red", lwd = 2)

# Marcar el pico en el gráfico
points(age_pico, performance_pico, col = "black", pch = 19, cex = 1.5)
text(age_pico, performance_pico, 
     labels = paste0(round(age_pico, 1), " años"), 
     pos = 3, col = "black")


```

## 3. Variable dicotómica para *sleep_hours*

```{r}

# Creamos sleep_group: 0 = <6h, 1 = ≥6h
datos$sleep_group <- ifelse(datos$sleep_hours < 6, 0, 1)

# Convertir a factor para que R lo trate como categoría
datos$sleep_group <- factor(datos$sleep_group, labels = c("<6h", "≥6h"))


```

Una vez creada la variable, la ajustaremos como predictora del modelo

```{r}

modelo_sueño <- lm(performance_index ~ sleep_group, data = datos)
summary(modelo_sueño)

```

Analizando la salida, vemos que los jugadores que han dormido más de 6 horas incrementan su rendimiento. El intercepto indica la media de rendimiento de jugadores con menos de 6 horas de sueño, mientras que el otro coeficiente (2.436) indica la diferencia entre los jugadores que han dormido más de 6 horas con respecto de aquellos que no. De esta manera, un mayor descanso deriva en un mejor rendimiento.

Por último, vamos a plantear un boxplot para visualizar mejor esta diferencia.

```{r}

boxplot(performance_index ~ sleep_group, data = datos,
        xlab = "Horas de sueño",
        ylab = "Performance Index",
        main = "Rendimiento según horas de sueño",
        col = c("lightblue", "lightgreen"))


```

## 4. *performance_index* frente a *fatigue* empleando un LOESS

```{r}

library(ggplot2)

ggplot(datos, aes(x = fatigue, y = performance_index)) +
  geom_point(color = "blue") +
  geom_smooth(method = "loess", color = "red", se = TRUE) +
  labs(title = "Rendimiento vs Fatigue con LOESS",
       x = "Fatigue",
       y = "Performance Index") +
  theme_minimal()


```

Podemos ver en la gráfica que la relación planteada es no lineal, con dos pequeños "picos" y un "valle" entre medias, y una posterior caída.

## 5. Spline sobre *training_hours* y comparación con método cuadrático

```{r}


# Ajustamos un spline cúbico con 4 knots por defecto
modelo_spline <- lm(performance_index ~ bs(training_hours, df = 4), data = datos)
summary(modelo_spline)


```

A continuación, graficaremos ambos modelos para ver la diferencia

```{r}

library(ggplot2)

ggplot(datos, aes(x = training_hours, y = performance_index)) +
  geom_point(color = "blue", alpha = 0.6) +  # puntos de datos
  stat_smooth(aes(color = "Cuadrático"), method = "lm", formula = y ~ poly(x, 2), se = FALSE, linetype = "dashed", size = 1) +
  stat_smooth(aes(color = "Spline"), method = "lm", formula = y ~ bs(x, 4), se = FALSE, size = 1) +
  scale_color_manual(name = "Modelo", values = c("Cuadrático" = "red", "Spline" = "darkgreen")) +
  labs(title = "Comparación: Modelo cuadrático vs Spline",
       x = "Training Hours", y = "Performance Index") +
  theme_minimal()


```

Vemos que el spline recoge mejor la no linealidad de la relación, ajustándose mejor a los valores reales.

Por otro lado, vamos a comparar formalmente ambos ajustes.

```{r}

# AIC
AIC(modelo_cuadratico_training, modelo_spline)

# R² ajustado
summary(modelo_cuadratico_training)$adj.r.squared
summary(modelo_spline)$adj.r.squared


```

Vemos que el AIC del modelo cuadrático es algo mayor, por lo que se ajusta un poco mejor a la relación. Sin embargo, el R\^2 del modelo spline es mayor, explicando más variabilidad.

La conclusión que podemos sacar es que ambos modelos son muy similares, explicando una variabilidad parecida. De esta manera, no parece que uno sea mucho mejor que el otro.

## 6. Piecewise en travel_km_week

En primer lugar, vamos a crear la variable dicotómica *travel_group*.

```{r}

datos$travel_group <- ifelse(datos$travel_km_week <= 1500, "≤1500", ">1500")

datos$travel_group <- factor(datos$travel_group, levels = c("≤1500", ">1500"))


```

A continuación, ajustaremos el modelo lineal con esta variable.

```{r}

modelo_piecewise <- lm(performance_index ~ travel_group, data = datos)
summary(modelo_piecewise)

```

Con la salida del modelo, vemos que el índice de rendimiento disminuye para aquellos jugadores que han viajado más de 1500 km a la semana. Esto se puede comprobar ya que el coeficiente asociado a esta variable es negativo (-5.9998). El valor de este coeficiente será la diferencia con los jugadores pertenecientes al otro grupo.

Finalmente, dispondremos un boxplot para ver la diferencia de manera visual.

```{r}

boxplot(performance_index ~ travel_group, data = datos,
        xlab = "Distancia semanal de viaje",
        ylab = "Performance Index",
        main = "Rendimiento según travel_km_week",
        col = c("lightblue", "lightgreen"))


```

## 7. Evaluación del AIC entre modelos lineal, cuadrático y piecewise para *training_hours*

Tenemos el modelo lineal y el cuadrático creados en anteriores apartados. Nos falta, por tanto, crear el modelo piecewise.

Para ello, en primer lugar crearemos la variable dicotómica *training_group*.

```{r}

datos$training_group <- ifelse(datos$training_hours <= 20, "≤20", ">20")
datos$training_group <- factor(datos$training_group, levels = c("≤20", ">20"))


```

Con esta, creamos el modelo piecewise

```{r}

modelo_piecewise_training <- lm(performance_index ~ training_group, data = datos)

```

Ahora, podremos comparar el AIC de estos modelos

```{r}

AIC(modelo_lineal_training, modelo_cuadratico_training, modelo_piecewise_training)

```

El modelo piecewise es el de mayor AIC, mientras que el cuadrático es el de menor AIC. De esta manera, el mejor modelo será el cuadrático, ya que es el que mejor combina ajuste y simplicidad.

## 8. Representación gráfica de las predicciones del modelo piecewise frente a las observaciones reales

En primer lugar, hacemos una predicción a partir del modelo piecewise

```{r}

# Inicializamos la variable, y la sustituimos donde no haya NA

datos$pred_piecewise_training <- NA  
datos$pred_piecewise_training[!is.na(datos$training_hours)] <- 
  predict(modelo_piecewise_training, newdata = datos[!is.na(datos$training_hours), ])


```

A continuación, hacemos la gráfica que permita ver la diferencia de esto frente a las observaciones reales.

```{r}
pred_group <- aggregate(pred_piecewise_training ~ training_group, datos, mean)

# Crear data frame para líneas horizontales
pred_lines <- data.frame(
  x = c(min(datos$training_hours_imputada), max(datos$training_hours_imputada),
        min(datos$training_hours_imputada), max(datos$training_hours_imputada)),
  y = c(pred_group$pred_piecewise_training[1], pred_group$pred_piecewise_training[1],
        pred_group$pred_piecewise_training[2], pred_group$pred_piecewise_training[2]),
  group_label = c("Grupo 1 (<20 h)", "Grupo 1 (<20 h)",
                  "Grupo 2 (>20 h)", "Grupo 2 (>20 h)")
)

# Gráfico
ggplot(datos, aes(x = training_hours_imputada)) +
  geom_point(aes(y = performance_index), alpha = 0.6, color = "steelblue") +
  geom_line(data = pred_lines, aes(x = x, y = y, color = group_label), linewidth = 1.2) +
  scale_color_manual(values = c("Grupo 1 (<20 h)" = "darkgreen", 
                                "Grupo 2 (>20 h)" = "firebrick")) +
  labs(title = "Predicciones del modelo piecewise vs. valores reales",
       x = "Training Hours",
       y = "Performance Index",
       color = "Grupo") +
  theme_minimal()





```

De esta manera, podemos ver las predicciones del modelo piecewise sobre las observaciones reales.

## 9. Ajuste de modelo lineal simple con casos completos

En primer lugar, vamos a ver cuántos casos perdemos por quedarnos solo con los completos.

```{r}

# Número total de filas
n_total <- nrow(datos)

# Casos completos
datos_completos <- datos[complete.cases(datos[, c("performance_index", "training_hours")]), ]

# Número de filas completas
n_completos <- nrow(datos_completos)

# Observaciones perdidas
n_perdidas <- n_total - n_completos

n_total
n_completos
n_perdidas



```

Vemos que perdemos 5 casos por valores faltantes.

A continuación, elaboramos el modelo´

```{r}

modelo_lineal_faltante <- lm(performance_index ~ training_hours, data = datos_completos)
summary(modelo_lineal_faltante)


```

## 10. Modelo con dataset imputado

Vamos a crear un dataset con todos los datos imputados

```{r}

# Crear copia del dataset original
datos_imputados <- datos

# Reemplazar variables con sus versiones imputadas
datos_imputados$training_hours <- training_hours_imputada
datos_imputados$fatigue <- fatigue_imputada_media
datos_imputados$sleep_hours <- sleep_imputada
datos_imputados$strength_1RM <- strength_1RM_imputada

# Imputar agility_time con la media
media_agility <- mean(datos$agility_time, na.rm = TRUE)
agility_time_imputada <- datos$agility_time
agility_time_imputada[is.na(agility_time_imputada)] <- media_agility
datos_imputados$agility_time <- agility_time_imputada


```

Ahora, planteamos el modelo con el nuevo dataset

```{r}

modelo_lineal_imputado <- lm(performance_index ~ training_hours, data = datos_imputados)
summary(modelo_lineal_imputado)

```

Cambia mínimamente el intercepto, pero es un cambio demasiado pequeño como para tenerlo en cuenta. Por otro lado, la pendiente sigue igual.

# 5. HETEROCEDASTICIDAD

## 1. Ajuste de modelo múltiple con gráfico de residuos

Vamos a crear el modelo múltiple con los datos imputados.

```{r}

modelo_multiple5.1 <- lm(
  performance_index ~ training_hours + match_intensity + strength_1RM + fatigue,
  data = datos_imputados
)

summary(modelo_multiple5.1)

```

A continuación, vamos a disponer el gráfico de residuos vs valores ajustados.

```{r}

ggplot(data = datos_imputados, aes(x = modelo_multiple5.1$fitted.values,
                                   y = modelo_multiple5.1$residuals)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_hline(yintercept = 0, color = "red", linewidth = 1) +
  labs(title = "Residuos vs Valores Ajustados (Modelo Múltiple)",
       x = "Valores ajustados",
       y = "Residuos") +
  theme_minimal()

```

En el gráfico podemos apreciar los residuos dispersos alrededor de 0 sin patrones aparentes, por lo que la relación lineal es razonable. Puede haber algo de heterocedasticidad, pero nada preocupante a priori.

## 2. Test de Breusch-Pagan

Aplicaremos al modelo recientemente creado el test mencionado para determinar si hay un problema de heterocedasticidad.

```{r}

bptest(modelo_multiple5.1)

```

El p-valor del test es muy elevado, por lo que no podemos rechazar la hipótesis de homocedasticidad. De esta manera, no podemos concluir que haya un problema de heterocedasticidad en el modelo.

## 3. Varianza de los residuos en la variable *fatigue*

Empezaremos extrayendo los residuos del modelo, dividiendo los casos en 3 niveles de fatiga (bajo, medio y alto) dividiendo la muestra en terciles para tomar grupos con el mismo número de muestras.

```{r}

# Residuos
residuos <- residuals(modelo_multiple5.1)

# Crear niveles bajo–medio–alto por terciles
datos_imputados$fatigue_grupo <- cut(
  datos_imputados$fatigue,
  breaks = quantile(datos_imputados$fatigue, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE),
  labels = c("Bajo", "Medio", "Alto"),
  include.lowest = TRUE
)


```

A continuación, calculamos la varianza de los residuos en cada uno de los grupos.

```{r}

tapply(residuos, datos_imputados$fatigue_grupo, var)


```

Vemos que las varianzas son similares, pero con ligeras variaciones. Sin embargo, vamos a concluir si la diferencia entre estas es estadísticamente significativa. Para ello, usaremos el test de Bartlett.

```{r}

bartlett.test(residuos ~ datos_imputados$fatigue_grupo)

```

Como el p-valor es muy elevado, no podemos afirmar que la diferencia de varianzas entre los residuos sea estadísticamente significativa.

## 4. Gráfica de residuos vs *sleep_hours*

```{r}

# Obtener los residuos del modelo
residuos <- residuals(modelo_multiple5.1)
ajustados <- fitted(modelo_multiple5.1)


ggplot(datos_imputados, aes(x = sleep_hours, y = residuos)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_smooth(method = "loess", se = FALSE, color = "red", linewidth = 1) +
  labs(title = "Residuos vs. Horas de sueño",
       x = "Horas de sueño",
       y = "Residuos") +
  theme_minimal()


```

En este caso, vemos como los residuos se alejan del 0, por lo que podemos detectar un ligero problema de heterocedasticidad; ya que la varianza de los residuos parece incrementar conforme lo hacen las horas de sueño.

De esta manera, podemos intuir que la varianza depende de las horas de sueño.

## 5. Modelo con errores estándar robusto (HC)

```{r}

# 1. Errores estándar clásicos
clasico <- summary(modelo_multiple5.1)$coefficients[, 2]

# 2. Errores estándar robustos (HC3)
robustos <- sqrt(diag(vcovHC(modelo_multiple5.1, type = "HC3")))

# 3. Comparación en un data frame
comparacion <- data.frame(
  Coeficiente = names(clasico),
  SE_Clasico = clasico,
  SE_Robusto_HC3 = robustos,
  Aumento_relativo = robustos / clasico
)

comparacion

```

Vemos que los errores de los coeficientes cambian considerablemente con respecto de los del modelo original.

## 6. Transformación logarítmica al predictor *travel_km_week*

En primer lugar, creamos la variable transformada (le sumamos 1 para que no haya valores iguales a 0 y pueda tomar logaritmos).

```{r}

datos_imputados$log_travel_km_week <- log(datos_imputados$travel_km_week+1)

```

A continuación, vamos a hacer el modelo con la variable ajustada

```{r}

modelo_multiple5.6 <- lm(
  performance_index ~ training_hours + match_intensity + strength_1RM + fatigue + log_travel_km_week,
  data = datos_imputados
)

# Resumen del modelo
summary(modelo_multiple5.6)

```

Para ver si mejora la heterocedasticidad dibujaremos la gráfica de residuos vs valores ajustados de este nuevo modelo

```{r}

# Para el modelo original
plot(modelo_multiple5.1$fitted.values, modelo_multiple5.1$residuals,
     xlab = "Valores ajustados", ylab = "Residuos",
     main = "Residuos vs valores ajustados (modelo original)")
abline(h = 0, col = "red")

# Para el modelo con log
plot(modelo_multiple5.6$fitted.values, modelo_multiple5.6$residuals,
     xlab = "Valores ajustados", ylab = "Residuos",
     main = "Residuos vs valores ajustados (modelo log)")
abline(h = 0, col = "red")


```

La gráfica es similar, pero podemos apreciar que los valores tienden a concetrarse en mayor medida en el centro de la gráfica. De esta manera, podemos intuir que se "corrige" un poco el ligero problema de heterocedasticidad que podíamos haber tenido antes.

De todas formas, vamos a verlo con el test Breusch-Pagan

```{r}

# Modelo original
bptest(modelo_multiple5.1)

# Modelo log-transformado
bptest(modelo_multiple5.6)

```

Como ambos p-valores son mucho mayores que 0.05, concluimos que no hay diferencia significativa a pesar del ligero aporte que se haya podido dar al modelo.

## 7. Estudio gráfico sobre la causa de la heterocedasticidad

Tomamos en primer lugar los residuos estandarizados.

```{r}

residuos5.6 <- rstandard(modelo_multiple5.6)

```

Ahora, vamos a ver si la heterocedasticidad depende de la fatiga

```{r}

plot(datos_imputados$fatigue, residuos,
     xlab = "Fatiga",
     ylab = "Residuos estandarizados",
     main = "Residuos vs Fatiga")
abline(h = 0, col = "red")

```

Los valores aparecen de manera uniforme sin patrones claros, por lo que los residuos de los jugadores con altos valores de fatiga no parecen sufrir de heterocedasticidad.

Por otro lado, vamos a ver si esta depende de las horas de sueño

```{r}

plot(datos_imputados$sleep_hours, residuos,
     xlab = "Horas de sueño",
     ylab = "Residuos estandarizados",
     main = "Residuos vs Sueño")
abline(h = 0, col = "red")

```

Los residuos de jugadores con pocas horas de sueño aparecen más dispersos que los valores de la anterior gráfica.

Por tanto, podemos concluir que el efecto de la heterocedasticidad es más acusado para jugadores con pocas horas de sueño que para aquellos con mucha fatiga.

## 8. Cómo afecta la heterocedasticidad

La heterocedasticidad es, por definición, el fenómeno ocurrido cuando la varianza de los errores cambia según los valores de los predictores.

En una primera instancia, esto implica que los estimadores de los coeficientes no sean de mínima varianza, perdiendo así eficacia.

De esta manera, la varianza obtenida a partir de los estimadores a la hora de hacer intervalos de confianza, se estimará incorrectamente; derivando en intervalos de confianza que no reflejen correctamente el umbral real.

Con respecto a los tests de significación, tenemos un problema similar. En este caso, lo que cambiará será el p-valor de los mismos. En particular, en caso de sobreestimar varianza, tendremos riesgos de encontrar falsos negativos (es decir, de no encontrar un efecto real) , y en caso de subestimar varianza estará el riesgo de encontrar falsos positivos (es decir, rechazar la hipótesis nula siendo cierta).

## 9. Posibilidad de recurrir a un GLM con varianza distinta a la normal para modelar *performance_index*

Sí, en algunos casos, recurrir a un GLM con varianza distinta a la normal puede ser conveniente. Esto es debido a que, usando un GLM adecuado, podemos separar la media de la varianza, permitiendo mejorar la eficiencia de los intervalos de confianza y tests.

Es decir, el uso de los GLM puede ayudar en caso de problemas con heterocedasticidad marcada, valores extremos o asimetría y restricciones de la variable.

## 10. Estrategia más adecuada

En este caso, lo mejor será dejar el modelo tal cual está, ya que no tenemos grandes problemas de heterocedasticidad que puedan dar lugar a errores posteriores con tests o intervalos de confianza.

De esta manera, al no haber heterocedasticidad marcada ni una gran diferencia entre residuos normales y robustos, lo mejor será mantener la regresión múltiple estándar.

# 6. MODELOS GLM

## 1. Modelo de Poisson para *injury_count*

Vamos a ajustar un modelo de Poisson para explicar la variable *injury_count* a partir de *training_hours* y *fatigue*.

```{r}

modelo_poisson <- glm(injuries_count ~ training_hours + fatigue,poisson(link="log"), data = datos, )

summary(modelo_poisson)

```

Con la salida del modelo, vamos a ver si los coeficientes son significativos. Como el p-valor del intercepto es muy bajo (\<0.05), significa que es significativo. Por el contrario, los otros coeficientes no lo serán, ya que su p-valor asociado es \>0.05.

## 2. Existencia de sobre-dispersión en el modelo de Poisson

El índice de dispersión viene determinado por el cociente entre la desviación residual y los grados de libertad de los residuos.

```{r}

modelo_poisson$deviance / modelo_poisson$df.residual

```

En este caso, el índice de dispersión es 0.9772406. De esta manera, al aproximarse a 1, la dispersión que presenta el modelo es adecuada.

## 3. Modelo de binomial negativa

```{r}

modelo_nb <- glm.nb(injuries_count ~ training_hours + fatigue, data = datos)
summary(modelo_nb)

```

Para ver cual es mejor, comapararemos el AIC de los modelos

```{r}

AIC(modelo_poisson, modelo_nb)

```

Ambos valores son similares, por lo que los modelos también lo serán. Sin embargo, el AIC del modelo binomial negativo es algo menor, por lo que el modelo será algo mejor que el modelo de Poisson.

## 4. Comparación de la devianza residual de los modelos de Poisson y NegBin

```{r}

cat("Poisson:    deviance =", deviance(modelo_poisson),
    "  df.resid =", modelo_poisson$df.residual, "\n")
cat("NegBin:     deviance =", deviance(modelo_nb),
    "  df.resid =", modelo_nb$df.residual, "\n")

# razón simple (devianza/df) para cada modelo
cat("Poisson: dev/df =", deviance(modelo_poisson) / modelo_poisson$df.residual, "\n")
cat("NegBin:  dev/df =", deviance(modelo_nb) / modelo_nb$df.residual, "\n")

# diferencia de devianzas y test de razón de verosimilitud (lrtest)
cat("Diferencia de devianzas (Poisson - NegBin) =",
    deviance(modelo_poisson) - deviance(modelo_nb), "\n")

# lrtest
lr <- lrtest(modelo_poisson, modelo_nb)
print(lr)

```

Vemos en la salida del test que el modelo NegBin tiene una devianza residual mucho menor que el modelo de Poisson. Esto implica que el modelo NegBin tiene un mejor ajuste que el de Poisson. Para confirmarlo, podemos ver también los ratios de devianza por cada grado de libertad (índices de devianza). Vemos que también es menor para el modelo NegBin, lo que cuadra con el resultado defendido.

Finalmente, con el *lrtest*, confirmamos que el modelo NegBin es mejor que el de Poisson, al tener un p-valor menor que 0.05.

## 5. Ratios para modelo de regresión logística

En primer lugar, creamos el modelo de regresión. Usaremos el conjunto de datos *datos_imputados*, para que no haya problemas posteriores con los valores faltantes.

```{r}

# Ajustar modelo logístico
modelo_starter <- glm(starter ~ training_hours + match_intensity + agility_time,
                    family = binomial(link = "logit"),
                    data = datos_imputados)

# Ver el resumen
summary(modelo_starter)


```

A continuación, vamos a calcular los ratios para el modelo

```{r}

# Odds ratios
exp(coef(modelo_starter))

# Intervalos de confianza para OR
exp(confint(modelo_starter))


```

Teniendo los ratios, vemos que las variables *training_hours* y *match_intensity* incrementan la posibilidad de ser jugador titular. Por otro lado, vemos que la variable *agility_time* tiene el efecto contrario. Es decir, esta variable disminiuye la probabilidad de ser titular en un partido.

Sin embargo, vemos que ninguna de las variables tiene un efecto significativo sobre la posibilidad de ser titular en un partido. Esto se debe a que los intervalos de confianza de todas las variables incluyen el valor 1. De esta manera, a pesar de poder influir, no lo hacen de forma estadísticamente significativa.

## 6. Representación de curva ROC y cálculo del AUC

En primer lugar, vamos a calcular las probabilidades predichas

```{r}

prob_pred <- predict(modelo_starter, type = "response")

```

A continuación, podemos crear la curva ROC.

```{r}

roc_obj <- roc(datos_imputados$starter, prob_pred)

# Dibujar la curva
plot(roc_obj, main = "Curva ROC - Modelo Logístico",
     col = "blue", lwd = 2)
abline(a=0, b=1, lty=2, col="gray")  # línea diagonal de referencia

```

Por otro lado, calcularemos el AUC.

```{r}

auc_val <- auc(roc_obj)
auc_val

```

Vamos a añadirlo a la gráfica para ver todos los resultados en la misma iamgen y poder interpretarlos.

```{r}

plot(roc_obj, main = paste("Curva ROC - AUC =", round(auc_val, 3)),
     col = "blue", lwd = 2)
abline(a=0, b=1, lty=2, col="gray")


```

De esta manera, vemos que el área bajo la curva ROC es de 0.64. Esto implica una discriminación baja, la cual puede ser mejorable, pero ya supone un modelo no aleatorio. De esta manera, podemos distinguir en cierto modo patrones que determinarán la titularidad o la suplencia de los jugadores atendiendo a las variables que tenemos en la base de datos.

## 7. Modelo binomial logit para la tasa de acierto en pases

```{r}

modelo_pases <- glm(
  cbind(passes_success, passes_attempted - passes_success) ~ agility_time + fatigue + position,
  family = binomial(link = "logit"),
  data = datos
)

# Resumen del modelo
summary(modelo_pases)

```

Con la salida del modelo, vemos que la tasa de acierto en pases viene determinada por varios factores. En particular, la variable *agility_time* influye muy negativamente en la tasa de acierto de pases. Por otro lado, la variable *fatigue* influye también negativamente, pero con un peso mucho menor.

Por otro lado, vemos que el efecto de la posición no tiene por qué influir de forma estadísticamente significativa, ya que el hecho de ser portero o delantero no explica la variación de la tasa de pases (p-valores muy elevados).

Finalmente, encontramos el único factor que influye positivamente, con un peso bastante alto, y es el hecho de ser centrocampista. Esta es la única posición que explica correctamente la variación de la tasa de acierto en pases.

## 8. Qué posición tiene mayor probabilidad de completar pases exitosos

Según la salida del modelo anterior, tal y como ya hemos comentado, la única posición que influye positivamente en la tasa de pases acertados es la de centrocampista.

De esta manera, la posición con mayor probabilidad de completar pases exitosos, será la de centrocampista.

## 9. Modelo logístico incluyendo sleep_hours

```{r}

modelo_sleep <- glm(starter ~ sleep_group,
                    family = binomial(link = "logit"),
                    data = datos)

# Ver resumen de los coeficientes
summary(modelo_sleep)

```

Vemos que el hecho de haber dormido más de 6 horas parece que influye positivamente en la probabilidad de ser titular. Sin embargo, vemos que el p-valor del coeficiente asociado a *sleep_group* es muy elevado. De esta manera, es una variable que no explica bien la variabilidad de la variable *starter*.

Así, podemos concliur que no hay evidencia significativa de que el descanso de los jugadores influya en la posibilidad de ser titular.

## 10. Ventajas de usar GLM frente a la regresión lineal para modelar variables como lesiones, titularidad o éxito en pases.

El hecho de usar GLM supone varias ventajas frente a la regresión lineal para modelar este tipo de variables. Entre estas ventajas, encontramos el hecho de que permite modelar correctamente la distribución correcta de la variable dependiente, así como el hecho de trabajar con ratios muy útiles para variables binarias (como hemos hecho con la variable *starter*).

Además, el hecho de usar GLM evita problemas de predicciones fuera de rango y errores de homocedasticidad, así como permite ajustar la varianza que depende de la media.

# 7. INTERACCIONES

## 1. Ajuste de modelo lineal para *performance_index* en función de *training_hours*X*match_intensity*

Ajustamos el modelo de interacción.

```{r}

modelo_perf <- lm(performance_index ~ training_hours * match_intensity, data = datos)

# Resumen del modelo
summary(modelo_perf)

```

A partir de la salida del modelo, vemos que el valor del intercepto (es decir, el índice de rendimiento sin la influencia de otras variables) es de 41.999437.

Por otro lado, podemos ver los valores de los coeficientes asociados a *training_hours* (muy elevado y positivo) y a *match_intensity* (negativo pero de bastante menor peso). Estos indican el valor que aportan si la otra variable vale 0.

Por último, encontramos el valor del coeficiente asociado a *training_hours:match_intensity*. Este tiene un valor de 0.011328. Al ser positivo, esto indica que el efecto de las horas de entrenamiento es mayor conforme incrementa el valor de *match_intensity*. Sin embargo, el p-valor nos indica que esto no es significativo, por lo que no lo consideraremos información relevante para explicar la variabilidad de *training_hours*.

## 2. Representación de la interacción anterior para distintos niveles de *match_intensity*

Empezaremos eligiendo los valores de *match_intensity* sobre los que graficaremos

```{r}

# Valores de intensidad (ejemplo: percentiles)
niveles_int <- quantile(datos$match_intensity, probs = c(0.25, 0.5, 0.75),
                         na.rm = TRUE)

# Grid de valores
newdata <- expand.grid(
  training_hours = seq(min(datos$training_hours, na.rm = TRUE),
                       max(datos$training_hours, na.rm = TRUE),
                       length.out = 100),
  match_intensity = niveles_int
)

# Predicciones
newdata$performance_pred <- predict(modelo_perf, newdata)

```

A continuación, graficaremos la interacción

```{r}

ggplot(newdata,
       aes(x = training_hours,
           y = performance_pred,
           color = factor(match_intensity))) +
  geom_line(size = 1.2) +
  labs(
    x = "Training hours",
    y = "Predicted performance index",
    color = "Match intensity",
    title = "Interaction between training hours and match intensity"
  ) +
  theme_minimal()


```

De esta manera, vemos que el coeficiente de interacción positivo se ve reflejado en el hecho de que, a mayor intensidad de partido, se estima un mayor índice de rendimiento. Sin embargo, no hay apenas diferencia, ya que, como hemos comentado previamente, el coeficiente de interacción no era estadísticamente significativo.

## 3. Ajuste de modelo logístico para *starter* a partir de *agility_time*x*strength_1RM*

Creamos el modelo logístico

```{r}

modelo_logit <- glm(starter ~ agility_time * strength_1RM,
                    family = binomial(link = "logit"),
                    data = datos)

# Resumen del modelo
summary(modelo_logit)

```

En el modelo podemos ver que el efecto de la interacción entre las variables *agility_time* y *strength_1RM* es positivo. Esto quiere decir que el de *agility_time* sobre la posibilidad de ser titular incrementa conforme el valor de *strength_time* es mayor. Sin embargo, una vez más el p-valor asociado a esta interacción es muy elevado, por lo que determinaremos que esta interacción no es estadísticamente significativa.

## 4. Representación gráfica de esta interacción en función de los niveles de agilidad

Seleccionamos los niveles de agilidad sobre los que graficaremos

```{r}

niveles_agility <- quantile(datos$agility_time, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)

# Crear grid de valores
newdata <- expand.grid(
  strength_1RM = seq(min(datos$strength_1RM, na.rm = TRUE),
                     max(datos$strength_1RM, na.rm = TRUE),
                     length.out = 100),
  agility_time = niveles_agility
)

# Predicciones de probabilidad
newdata$prob <- predict(modelo_logit, newdata, type = "response")

```

A continuación, planteamos las gráficas correspondientes

```{r}

ggplot(newdata, aes(x = strength_1RM,
                    y = prob,
                    color = factor(agility_time))) +
  geom_line(size = 1.2) +
  labs(x = "Strength 1RM (kg)",
       y = "Probability of being starter",
       color = "Agility (s)",
       title = "Interaction: Agility x Strength on Starter Probability") +
  theme_minimal()


```

En este caso, volvemos a ver el mismo efecto. Como el efecto de la interacción es positivo, a mayor nivel de *agility_time*, mayor será la probabilidad de ser titular. En este caso, la diferencia es algo mayor, y se ve condicionada también por el tipo de modelo planteado (logístico).

Sin embargo, los cambios son sutiles y comienzan a distinguirse con valores altos de la variable *strength_1RM*.

## 5. Modelo binomial para la tasa de éxito de pases

```{r}

modelo_pases <- glm(
  cbind(passes_success, passes_attempted - passes_success) ~ fatigue * position,
  family = binomial(link = "logit"),
  data = datos_imputados
)

# Resumen del modelo
summary(modelo_pases)

```

Vamos a analizar los coeficientes obtenidos paso a paso. En primer lugar vemos que, sin factores externos, la tasa de acierto en pases (para defensas) es de un 65% aproximadamente. Por otro lado, la fatiga tiene un coeficiente asociado de valor 0.016562. Vemos que este es estadísticamente significativo, por lo que la fatiga tiene un efecto negativo de cara a la tasa de acierto de pases.

Por otro lado, vemos que el resto de posiciones tienen una tasa mayor de acierto que la de los defensas, ya que sus coeficientes asociados son todos positivos, aunque vemos que no son estadísticamente significativos a la hora de determinar el valor de la tasa de pases.

Por último, nos fijaremos en las interacciones. Vemos que el efecto de la fatiga sobre los porteros y delanteros es negativo de cara a la tasa de acierto en los pases (respecto a los defensas). Sin embargo, por otro lado, vemos que la fatiga influye de manera más positiva para los centrocampistas que para los defensas. Esto se debe, seguramente, a que son los encargados de crear el juego y organizarlo; especialmente en los momentos complicados y donde físicamente los jugadores están más exigidos. Así, se prevé que tomarán mejores decisiones en estos momentos que el resto de jugadores.

Sin embargo, un importante matiz a añadir es que ninguna de estas interacciones es estadísticamente significativa, al igual que en modelos anteriores. Así, nos servirá para ver cómo influye la fatiga sobre las posiciones, pero no concluirá de manera significativa la variación de la tasa de acierto de pases.

Vemos el efecto de la fatiga por posición con una gráfica

```{r}

newdata <- expand.grid(
  fatigue = seq(min(datos_imputados$fatigue), max(datos_imputados$fatigue), length.out = 50),
  position = levels(datos_imputados$position)
)

# Predicciones de probabilidad
newdata$prob <- predict(modelo_pases, newdata, type = "response")

# Gráfico
ggplot(newdata, aes(x = fatigue, y = prob, color = position)) +
  geom_line(size = 1.2) +
  labs(x = "Fatigue",
       y = "Probability of successful pass",
       color = "Position",
       title = "Effect of fatigue on passing success by position") +
  theme_minimal()

```

Vemos que se obtienen los resultados esperados, tal y como se comentó anteriormente.

## 6. ¿Por qué las interacciones son especialmente importantes en el ámbito deportivo?

En el mundo deportivo hay una gran cantidad de variables que permiten medir y distinguir jugadores. Las variables permiten diferenciar por sí solas entre jugadores, pero normalmente todas estas vienen condicionadas por otros aspectos. Con las interacciones, podemos explicar mejor tendencias y recoger diferencias entre grupos de jugadores, ya que explica el por qué de ciertos valores y permite entender la naturaleza del juego. Así, podríamos obtener una mejora considerable en modelos predictivos.

Además, hay que tener en cuenta todas las condiciones de los jugadores, ya que de cara a futuras competiciones, si queremos hacer un estudio del jugador, hay que tener todo en cuenta. Es decir, no hay que tener solo en cuenta los factores aislados, sino entender como estos se combinan y se potencian o limitan, de cara a la preparación para competiciones o para el desempeño en las mismas.

# 8. VARIABLES CATEGÓRICAS

## 1. Modelo lineal para *performance_index* a partir de *position*

Ajustamos el modelo

```{r}

modelo_perf <- lm(performance_index ~ position, data = datos)

# Resumen del modelo
summary(modelo_perf)

```

Según este modelo, el puesto con mejor rendimiento en el campo es el de portero. Esto se debe a que es el único puesto con coeficiente positivo. Es decir, es la única posición con mayor índice de rendimiento que la posición de defensa.

## 2. Añadimos *training_hours* y *match_intensity* al modelo

```{r}

modelo_perf2 <- lm(performance_index ~ position + training_hours + match_intensity, 
                   data = datos)

# Resumen
summary(modelo_perf2)

```

Tras añadir estas variables, vemos que el efecto de la posición ha cambiado considerablemente. Ahora, la posición con peor índice de rendimiento será la de defensa, seguida de los porteros. Por otro lado, la posición de centrocampista será la segunda con mayor índice de rendimiento, únicamente superada por los delanteros.

Estos cambios se deben a que ahora entran también en juego las otras variables, que afectan de manera diferente a todos estos grupos de jugadores. Esto está relacionado con la necesidad de estudiar las interacciones comentada en el apartado 8.6.

## 3. Modelo de *performance_index* en función de los equipos

Ajustamos el modelo

```{r}

modelo_team <- lm(performance_index ~ team, data = datos)

# Resumen
summary(modelo_team)

```

Vemos que los jugadores del equipo A tienen un índice de rendimiento de 58.4390 (el valor del intercepto). Por otro lado, los jugadores del equipo C tienen un valor de 1.0348 unidades mayor que el equipo A en lo referente a *performance_index* (en total tienen un valor de 59.4738). Este equipo solo se ve superado por el equipo C, con un valor de 1.4689 más que el equipo A (en total, 59.9079).

De esta manera, concluiremos que el mejor equipo (por índice de rendimiento) será el equipo C, seguido de el equipo B, mientras que el equipo A será el peor de los 3.

## 4. Introducción de *left_footed* como predictor en el modelo

```{r}

modelo_perf_zurdos <- lm(performance_index ~ left_footed, data = datos)

# Resumen del modelo
summary(modelo_perf_zurdos)

```

Vemos que el p-valor asociado a la variable *left_footed* es muy elevado, por lo que no hay evidencia de que los jugadores zurdos tengan un rendimiento significativamente diferente a los diestros.

## 5. Modelo que incluye a *team* y *position*

Ajustamos el modelo.

```{r}

# Modelo lineal con team y position
modelo_team_position <- lm(performance_index ~ team + position, data = datos)

# Resumen
summary(modelo_team_position)


```

A partir de la salida del modelo, podemos concluir que los coeficientes de los equipos tienen un valor menor que en el modelo que solo incluía a los equipos, por lo que podemos ver que tendrá un menor peso sobre el índice de rendimiento que en el modelo previo. Sin embargo, las diferencias no son notables a simple vista. Asimismo, el intercepto también es algo menor que en este modelo.

Por otro lado, comparando el modelo con aquel que solo incluía las posiciones, encontramos un efecto similar. Los coeficientes (tanto los de los valores de las variables categóricas como el intercepto) tenián un valor mayor, dando a entender que en este modelo conjunto tienen un menor peso que por separado. 

Aún así, no podemos concluir que haya evidencias notables con los otros modelos. Simplemente hay pequeños cambios que implican un menor peso para los valores de las variables.


## 6. Gráfico de cajas de *performance_index* por posición

Representamos el gráfico

```{r}

ggplot(datos, aes(x = position, y = performance_index, fill = position)) +
  geom_boxplot(alpha = 0.7) +
  labs(
    x = "Position",
    y = "Performance index",
    title = "Distribution of performance index by position"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

```

En el gráfico representado vemos los resultados esperados por los modelos anteriores. Es decir, la posición *defender* tiene la mediana en torno al valor 59 de *performance_index*, que se corresponde con el valor del intercepto del modelo. Por otro lado, la posición *forward* parece suponer un valor más elevado de esta variable, lo cual coincide con el modelo.

En cuanto a la posición *goalkeeper*, es en la única que podemos encontrar discrepancias. Esto se debe al valor negativo del coeficiente asociado a esta posición en el modelo por posiciones, frente al hecho de la distribución encontrada en el gráfico. Sin embargo, podemos asociar este hecho al elevado p-valor del modelo.

Por último, la posición *midfielder* también se ajusta a lo visto anteriormente en el modelo, presentando valores ligeramente inferiores a los defensas.


# 9. EVALUACIÓN Y COMPARACIÓN DE MODELOS

## 1. División del dataset

Vamos a dividir el conjunto de datos en un conjunto de entrenamiento del 70% y un conjunto de prueba del 30%.

```{r}

set.seed(123)  # Para reproducibilidad

n <- nrow(datos)

# Índices aleatorios para entrenamiento
train_index <- sample(seq_len(n), size = 0.7 * n)

# Conjuntos
datos_train <- datos[train_index, ]
datos_test  <- datos[-train_index, ]

```


## 2. Modelo para *performance_index* a partir de *training_hours*

Ajustamos el modelo

```{r}

modelo_simple <- lm(performance_index ~ training_hours, data = datos_train)

summary(modelo_simple)


```

## 3. Modelo múltiple de *performance_index* con términos cuadráticos

Ajustamos el modelo

```{r}

modelo_cuadratico <- lm(
  performance_index ~ training_hours + I(training_hours^2) +
    match_intensity + fatigue,
  data = datos_train
)

summary(modelo_cuadratico)


```

## 4. Cálculo de RMSE y MAE de los modelos en el conjunto de prueba

En primer lugar, hacemos las predicciones

```{r}

# Predicciones
pred_simple <- predict(modelo_simple, newdata = datos_test)
pred_cuadratico <- predict(modelo_cuadratico, newdata = datos_test)


```

A continuación, calculamos el RMSE y el MAE

```{r}

# Funciones
rmse <- function(obs, pred) {
  sqrt(mean((obs - pred)^2, na.rm = TRUE))
}

mae <- function(obs, pred) {
  mean(abs(obs - pred), na.rm = TRUE)
}

# Métricas
rmse_simple <- rmse(datos_test$performance_index, pred_simple)
mae_simple  <- mae(datos_test$performance_index, pred_simple)

rmse_cuad <- rmse(datos_test$performance_index, pred_cuadratico)
mae_cuad  <- mae(datos_test$performance_index, pred_cuadratico)


```

A continuación, comparamos los resultados

```{r}

resultados <- data.frame(
  Modelo = c("Lineal simple", "Cuadrático múltiple"),
  RMSE = c(rmse_simple, rmse_cuad),
  MAE  = c(mae_simple, mae_cuad)
)

resultados


```

Vemos que tanto el RMSE como el MAE del modelo lineal simple es mayor que el del modelo cuadrático simple.

De esta manera, el modelo cuadrático será mejor que el simple.


## 5. Comparación de modelos con AIC y BIC

Calculamos el AIC y el BIC de ambos modelos

```{r}

AIC(modelo_simple, modelo_cuadratico)
BIC(modelo_simple, modelo_cuadratico)


```

Tanto el AIC como el BIC del modelo cuadrático son menores. Esto, de la misma manera que el RMSE y el MAE, indican que el modelo cuadrático es mejor modelo que el simple.


## 6. Modelo con variables categóricas

Ajustamos el modelo

```{r}

modelo_completo <- lm(
  performance_index ~ training_hours + match_intensity + fatigue +
    position + team,
  data = datos_train
)

summary(modelo_completo)


```

Para ver si mejora el ajuste, lo compararemos el RMSE, el MAE, el BIC y el AIC con los modelos anteriores.

En primer lugar, hacemos la predicción a partir de este modelo en el conjunto de prueba

```{r}

pred_completa <- predict(modelo_completo, newdata = datos_test)

```

Por otro lado, calcularemos el RMSE y el MAE de la predicción con el nuevo modelo

```{r}

rmse_completo <- rmse(datos_test$performance_index, pred_completa)
mae_completo  <- mae(datos_test$performance_index, pred_completa)

```

Con esto, podemos compararlo con el RMSE y el MAE de los otros modelos

```{r}

resultados <- data.frame(
  Modelo = c("Lineal simple", "Cuadrático múltiple", "Completo"),
  RMSE = c(rmse_simple, rmse_cuad, rmse_completo),
  MAE  = c(mae_simple, mae_cuad, mae_completo)
)

resultados

```

Vemos que el RMSE y el MAE de este modelo completo es mayor que el de los otros dos, por lo que entendemos que será peor modelo.

Para terminar la comparación, estudiaremos el AIC y el BIC

```{r}

AIC(modelo_simple, modelo_cuadratico, modelo_completo)
BIC(modelo_simple, modelo_cuadratico, modelo_completo)

```

Vemos que el AIC y el BIC de este modelo son mayores que los del cuadrático. Así, el mejor modelo seguirá siendo el cuadrático, por lo que la introducción de las variables categóricas no mejora el ajuste.


## 7. Representación gráfica de las predicciones vs valores reales

Como el mejor modelo es el cuadrático, representaremos las predicciones sobre ese modelo.

```{r}

ggplot(datos_test, aes(x = pred_cuadratico, y = performance_index)) +
  geom_point(alpha = 0.6) +
  geom_abline(
    intercept = 0,
    slope = 1,
    color = "red",
    linetype = "dashed",
    linewidth = 1
  ) +
  labs(
    x = "Predicción performance_index",
    y = "Observaciones performance_index",
    title = "Predicciones vs observaciones performance_index (Quadratic model – Test set)"
  ) +
  theme_minimal()

```



# 10. PROYECTO INTEGRADOR

## 1. Elección de la variable respuesta

La variable respuesta elegida para el estudio realizado a continuación será *performance_index*.


## 2. Hipótesis sobre los predictores

A continuación, se va a plantear una lista de predictores que se han considerado adecuados para explicar la variable *performance_index*. Estas variables estarán agrupadas en varios sectores. Cada uno de ellos supone un aspecto fundamental para explicar la variable en cuestión. Así, las variables elegidas se mostrarán a continuación.

En primer lugar, hemos elegido *training_hours*, *match_intensity* y *fatigue* como variables asociadas a la carga física y a la exigencia competitiva de los jugadores.

Por otro lado, *sleep_hours*, *nutrition_score* y la variable *previous_injuries* están asociados a la nutrición, al descanso del jugador y al estado del jugador. Es decir, son variables determinantes para la recuperación y la salud de los mismos.

Las últimas variables elegidas han sido *strength_1RM* y *agility_time*, que muestran las capacidades físicas de los jugadores.

Con estas variables, plantearemos el primer modelo para *performance_index*.


## 3. Exploración descriptiva

### Media, mediana, desviación estándar, máximo y mínimo de las variables

Para ello, vamos a estudiar varias cosas. En primer lugar, veremos la media, desviación estándar, el mínimo, el máximo y la mediana de cada variable elegida para el modelo.

```{r}

datos |>
  dplyr::select(
    performance_index,
    training_hours,
    match_intensity,
    fatigue,
    sleep_hours,
    nutrition_score,
    strength_1RM,
    agility_time,
    injuries_count
  ) |>
  summarise(across(
    everything(),
    list(
      mean = mean,
      sd = sd,
      min = min,
      max = max,
      median = median
    ),
    na.rm = TRUE
  ))

```

Una vez vistos estos valores, como disponemos de variables continuas, vamos a estudiar su distribución.

### Distribuciones de las variables

#### *performance_index*

En primer lugar, veremos la de la variable *performance_index*

```{r}

ggplot(datos, aes(x = performance_index)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución del Performance Index",
    x = "Performance Index",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )
```

Vemos que tenemos una distribución aproximadamente normal. Esto nos hará decantarnos, a priori, por una regresión lineal. 

Sin embargo, nos falta todavía estudiar la distribución del resto de predictores, para entender su naturaleza y detectar posibles problemas y transformaciones. 

#### *training_hours*

```{r}

ggplot(datos, aes(x = training_hours)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución de las horas de entrenamiento",
    x = "training_hours",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

Una vez más, la distribución es aproximadamente normal. Por tanto, trabajaremos con esta variable sin aplicar transformaciones, al no encontrar situaciones preocupantes.

#### *match_intensity*

```{r}

ggplot(datos, aes(x = match_intensity)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución de intensidad de los partidos",
    x = "match_intensity",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

Una vez más, la distribución es aproximadamente normal. Por tanto, trabajaremos con esta variable sin aplicar transformaciones, al no encontrar situaciones preocupantes.

#### *fatigue*

```{r}

ggplot(datos, aes(x = fatigue)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución de la fatiga",
    x = "fatigue",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

En este caso, la distribución parece una normal bimodal. Vamos a ajustar un gráfico LOESS para ver si la relación no es lineal con *performance_index*

```{r}

ggplot(datos, aes(x = fatigue, y = performance_index)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess")


```

Con este gráfico vemos que, efectivamente, la relación no es lineal. Así, la fatiga tiene zonas de picos con el rendimiento, difícilmente recogibles con una relación lineal.

#### *sleep_hours*

```{r}

ggplot(datos, aes(x = sleep_hours)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución de horas de sueño",
    x = "sleep_hours",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

Una vez más, la distribución es aproximadamente normal. Por tanto, trabajaremos con esta variable sin aplicar transformaciones, al no encontrar situaciones preocupantes.

#### *nutrition_score*

```{r}

ggplot(datos, aes(x = nutrition_score)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución de la puntuación de la nutrición",
    x = "nutrition_score",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

En este caso encontramos una distribución con valores muy dispares. Podemos intuir una leve distribución normal, pero por si acaso vamos a ver el *QQ-plot* de esta variable.

```{r}

ggplot(datos, aes(sample = nutrition_score)) +
  stat_qq(color = "#2C7FB8", alpha = 0.6) +
  stat_qq_line(color = "#D95F0E", linewidth = 1) +
  labs(
    title = "Q–Q plot de nutrition_score",
    x = "Cuantiles teóricos",
    y = "Cuantiles muestrales"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
  )


```

Como vemos, las observaciones siguen la línea del *QQ-plot*, exceptuando algunas en las colas que pueden ser las culpables de alterar la normalidad en el histograma. Sin embargo, si quitamos estas pocas observaciones, el resto presentan una normalidad muy marcada.

#### *previous_injuries*

```{r}

ggplot(datos, aes(x = previous_injuries)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución del número de lesiones previas",
    x = "previous_injuries",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

En este caso, tenemos una variable entera, donde la mayoría de observaciones son de valor 0. La distribución es la esperada, pero para hacernos una idea de los jugadores con lesiones, vamos a mirar el porcentaje de jugadores sin lesiones y el porcentaje de jugadores que ha sufrido alguna lesión.

```{r}

# Total de observaciones
total <- nrow(datos)

# Observaciones donde injuries_count es 0
porc_cero <- sum(datos$previous_injuries == 0) / total * 100

# Observaciones donde injuries_count es distinto de 0
porc_distinto_cero <- sum(datos$previous_injuries != 0) / total * 100

porc_cero
porc_distinto_cero


```

Así, el 28.21497% de los jugadores no han sufrido ninguna lesión, mientras que el 71.78503% restante sí. A continuación, veremos el porcentaje de cada valor, dentro del grupo de jugadores que ha sufrido alguna lesión.

```{r}

datos %>%
  filter(previous_injuries != 0) %>%
  group_by(previous_injuries) %>%
  summarise(count = n()) %>%
  mutate(porcentaje = count / sum(count) * 100)


```

Estos son los porcentajes de cada valor del grupo de jugadores con lesiones previas. Si hiciésemos la distribución de este grupo, obtendríamos una similar a la de la población general, pero empezando en el 1.

Cabe destacar la presencia de posibles *outliers*, ya que hay jugadores con valores muy elevados de lesiones previas.

Por último, vamos a aplicar una transformación por el logaritmo, con fin de lograr la normalidad.

```{r}

datos$previous_injuries_log <- log(datos$previous_injuries +1)

ggplot(datos, aes(x = previous_injuries_log)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución del logaritmo de lesiones previas",
    x = "previous_injuries_log",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

No hemos logrado demasiado, debido a los pocos valores elevados, y al alto número de observaciones en el valor 0.

#### *strength_1RM*

```{r}

ggplot(datos, aes(x = strength_1RM)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución de la fuerza de los jugadores",
    x = "strength_1RM",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```

Una vez más, la distribución es aproximadamente normal. Por tanto, trabajaremos con esta variable sin aplicar transformaciones, al no encontrar situaciones preocupantes.

#### *agility_time*

```{r}

ggplot(datos, aes(x = agility_time)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 30,
    fill = "#69b3a2",
    color = "white",
    alpha = 0.7
  ) +
  geom_density(
    color = "#1f4e5f",
    linewidth = 1.2
  ) +
  labs(
    title = "Distribución del tiempo en test de agilidad",
    x = "agility_time",
    y = "Densidad"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

```


Una vez más, la distribución es aproximadamente normal. Por tanto, trabajaremos con esta variable sin aplicar transformaciones, al no encontrar situaciones preocupantes.

### Outliers

A continuación vemos si hay outliers. Empezaremos con la variable respuesta *performance_index*

#### *performance_index*

```{r}

outliers <- boxplot.stats(datos$performance_index)$out
outlier_data <- datos %>% filter(performance_index %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = performance_index)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = performance_index), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = performance_index, label = round(performance_index, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado del Performance Index",
    y = "Performance Index",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay unos cuantos ouliers de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$performance_index)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!performance_index %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$performance_index)
mediana_con <- median(datos$performance_index)

media_sin <- mean(datos_sin_outliers$performance_index)
mediana_sin <- median(datos_sin_outliers$performance_index)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE)) -
                        mean(sample(y, length(y), replace = TRUE)))
  mean(diffs >= (mean(x) - mean(y)))
}

# P-valor aproximado
p_valor <- bootstrap_diff(datos$performance_index, datos_sin_outliers$performance_index)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, hacemos lo propio para la mediana.

```{r}

set.seed(123)

bootstrap_median_diff <- function(x, y, n = 10000) {
  diffs <- replicate(n, median(sample(x, length(x), replace = TRUE)) -
                        median(sample(y, length(y), replace = TRUE)))
  mean(diffs >= (median(x) - median(y)))
}

p_valor_mediana <- bootstrap_median_diff(datos$performance_index, datos_sin_outliers$performance_index)
p_valor_mediana


```

Una vez más, el p-valor es muy elevado, por lo que concluímos que la diferencia tampoco será estadísticamente significativa.

#### *training_hours*

```{r}

outliers <- boxplot.stats(datos$training_hours)$out
outlier_data <- datos %>% filter(training_hours %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = training_hours)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = training_hours), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = training_hours, label = round(training_hours, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de training_hours",
    y = "training_hours",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay unos cuantos ouliers de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$training_hours)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!training_hours %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$training_hours, na.rm = TRUE)
mediana_con <- median(datos$training_hours, na.rm = TRUE)

media_sin <- mean(datos_sin_outliers$training_hours, na.rm = TRUE)
mediana_sin <- median(datos_sin_outliers$training_hours, na.rm = TRUE)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        mean(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)))
}


# P-valor aproximado
p_valor <- bootstrap_diff(datos$training_hours, datos_sin_outliers$training_hours)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, hacemos lo propio para la mediana.

```{r}

set.seed(123)

bootstrap_median_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, median(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        median(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (median(x, na.rm = TRUE) - median(y, na.rm = TRUE)))
}

p_valor_mediana <- bootstrap_median_diff(datos$training_hours, datos_sin_outliers$training_hours)
p_valor_mediana



```

Una vez más, el p-valor es muy elevado, por lo que concluímos que la diferencia tampoco será estadísticamente significativa.

#### *match_intensity*

```{r}

outliers <- boxplot.stats(datos$match_intensity)$out
outlier_data <- datos %>% filter(match_intensity %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = match_intensity)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = match_intensity), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = match_intensity, label = round(match_intensity, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de match_intensity",
    y = "match_intensity",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay unos dos *ouliers* de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$match_intensity)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!match_intensity %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$match_intensity, na.rm = TRUE)
mediana_con <- median(datos$match_intensity, na.rm = TRUE)

media_sin <- mean(datos_sin_outliers$match_intensity, na.rm = TRUE)
mediana_sin <- median(datos_sin_outliers$match_intensity, na.rm = TRUE)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        mean(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)))
}


# P-valor aproximado
p_valor <- bootstrap_diff(datos$match_intensity, datos_sin_outliers$match_intensity)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, hacemos lo propio para la mediana.

```{r}

set.seed(123)

bootstrap_median_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, median(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        median(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (median(x, na.rm = TRUE) - median(y, na.rm = TRUE)))
}

p_valor_mediana <- bootstrap_median_diff(datos$match_intensity, datos_sin_outliers$match_intensity)
p_valor_mediana



```

Una vez más, el p-valor es muy elevado, por lo que concluímos que la diferencia tampoco será estadísticamente significativa.

#### *fatigue*

```{r}

outliers <- boxplot.stats(datos$fatigue)$out
outlier_data <- datos %>% filter(fatigue %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = fatigue)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = fatigue), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = fatigue, label = round(fatigue, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de fatigue",
    y = "fatigue",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay un oulier de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$fatigue)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!fatigue %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$fatigue, na.rm = TRUE)
mediana_con <- median(datos$fatigue, na.rm = TRUE)

media_sin <- mean(datos_sin_outliers$fatigue, na.rm = TRUE)
mediana_sin <- median(datos_sin_outliers$fatigue, na.rm = TRUE)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        mean(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)))
}


# P-valor aproximado
p_valor <- bootstrap_diff(datos$fatigue, datos_sin_outliers$fatigue)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, hacemos lo propio para la mediana.

```{r}

set.seed(123)

bootstrap_median_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, median(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        median(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (median(x, na.rm = TRUE) - median(y, na.rm = TRUE)))
}

p_valor_mediana <- bootstrap_median_diff(datos$fatigue, datos_sin_outliers$fatigue)
p_valor_mediana



```

Una vez más, el p-valor es muy elevado, por lo que concluímos que la diferencia tampoco será estadísticamente significativa.

#### *sleep_hours*

```{r}

outliers <- boxplot.stats(datos$sleep_hours)$out
outlier_data <- datos %>% filter(sleep_hours %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = sleep_hours)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = sleep_hours), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = sleep_hours, label = round(sleep_hours, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de sleep_hours",
    y = "sleep_hours",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay unos cuantos ouliers de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$sleep_hours)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!sleep_hours %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$sleep_hours, na.rm = TRUE)
mediana_con <- median(datos$sleep_hours, na.rm = TRUE)

media_sin <- mean(datos_sin_outliers$sleep_hours, na.rm = TRUE)
mediana_sin <- median(datos_sin_outliers$sleep_hours, na.rm = TRUE)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        mean(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)))
}


# P-valor aproximado
p_valor <- bootstrap_diff(datos$sleep_hours, datos_sin_outliers$sleep_hours)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, hacemos lo propio para la mediana.

```{r}

set.seed(123)

bootstrap_median_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, median(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        median(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (median(x, na.rm = TRUE) - median(y, na.rm = TRUE)))
}

p_valor_mediana <- bootstrap_median_diff(datos$sleep_hours, datos_sin_outliers$sleep_hours)
p_valor_mediana



```

Una vez más, el p-valor es muy elevado, por lo que concluímos que la diferencia tampoco será estadísticamente significativa.

#### *nutrition_score*

```{r}

outliers <- boxplot.stats(datos$nutrition_score)$out
outlier_data <- datos %>% filter(nutrition_score %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = nutrition_score)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = nutrition_score), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = nutrition_score, label = round(nutrition_score, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de nutrition_score",
    y = "nutrition_score",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay un oulier de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$nutrition_score)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!nutrition_score %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$nutrition_score, na.rm = TRUE)
mediana_con <- median(datos$nutrition_score, na.rm = TRUE)

media_sin <- mean(datos_sin_outliers$nutrition_score, na.rm = TRUE)
mediana_sin <- median(datos_sin_outliers$nutrition_score, na.rm = TRUE)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        mean(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)))
}


# P-valor aproximado
p_valor <- bootstrap_diff(datos$nutrition_score, datos_sin_outliers$nutrition_score)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, hacemos lo propio para la mediana.

```{r}

set.seed(123)

bootstrap_median_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, median(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        median(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (median(x, na.rm = TRUE) - median(y, na.rm = TRUE)))
}

p_valor_mediana <- bootstrap_median_diff(datos$nutrition_score, datos_sin_outliers$nutrition_score)
p_valor_mediana



```

Una vez más, el p-valor es muy elevado, por lo que concluímos que la diferencia tampoco será estadísticamente significativa.

#### *previous_injuries*

```{r}

outliers <- boxplot.stats(datos$previous_injuries)$out
outlier_data <- datos %>% filter(previous_injuries %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = previous_injuries)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = previous_injuries), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = previous_injuries, label = round(previous_injuries, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de previous_injuries",
    y = "previous_injuries",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay unos cuantos ouliers de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$previous_injuries)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!previous_injuries %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$previous_injuries, na.rm = TRUE)
mediana_con <- median(datos$previous_injuries, na.rm = TRUE)

media_sin <- mean(datos_sin_outliers$previous_injuries, na.rm = TRUE)
mediana_sin <- median(datos_sin_outliers$previous_injuries, na.rm = TRUE)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        mean(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)))
}


# P-valor aproximado
p_valor <- bootstrap_diff(datos$previous_injuries, datos_sin_outliers$previous_injuries)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, la mediana es exactamente la misma, por lo que no haremos test en esta ocasión.


#### *strength_1RM*

```{r}

outliers <- boxplot.stats(datos$strength_1RM)$out
outlier_data <- datos %>% filter(strength_1RM %in% outliers)

datos$x <- 1
outlier_data$x <- 1

ggplot(datos, aes(x = factor(x),y = strength_1RM)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = strength_1RM), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = strength_1RM, label = round(strength_1RM, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de strength_1RM",
    y = "strength_1RM",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que hay unos cuantos ouliers de esta variable. Vamos a ver si los valores de la media y de la mediana varían mucho sin *outliers* frente a los obtenidos con *outliers*.

```{r}

outliers <- boxplot.stats(datos$strength_1RM)$out

# Dataframe sin outliers
datos_sin_outliers <- datos %>% filter(!strength_1RM %in% outliers)

# Calcular estadísticas
media_con <- mean(datos$strength_1RM, na.rm = TRUE)
mediana_con <- median(datos$strength_1RM, na.rm = TRUE)

media_sin <- mean(datos_sin_outliers$strength_1RM, na.rm = TRUE)
mediana_sin <- median(datos_sin_outliers$strength_1RM, na.rm = TRUE)

# Crear tabla 2x2
tabla_2x2 <- data.frame(
  Estadística = c("Media", "Mediana"),
  Con_Outliers = c(media_con, mediana_con),
  Sin_Outliers = c(media_sin, mediana_sin)
)

# Mostrar la tabla
tabla_2x2

```

Vamos a ver si la diferencia de medias es estadísticamente significativa con un test bootstrap.

```{r}

set.seed(123)

# Función para bootstrap
bootstrap_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, mean(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        mean(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (mean(x, na.rm = TRUE) - mean(y, na.rm = TRUE)))
}


# P-valor aproximado
p_valor <- bootstrap_diff(datos$strength_1RM, datos_sin_outliers$strength_1RM)
p_valor


```
El p-valor es muy elevado, por lo que conluímos que no lo es.

Por otro lado, hacemos lo propio para la mediana.

```{r}

set.seed(123)

bootstrap_median_diff <- function(x, y, n = 10000) {
  x <- na.omit(x)
  y <- na.omit(y)
  diffs <- replicate(n, median(sample(x, length(x), replace = TRUE), na.rm = TRUE) -
                        median(sample(y, length(y), replace = TRUE), na.rm = TRUE))
  mean(diffs >= (median(x, na.rm = TRUE) - median(y, na.rm = TRUE)))
}

p_valor_mediana <- bootstrap_median_diff(datos$strength_1RM, datos_sin_outliers$strength_1RM)
p_valor_mediana



```

Una vez más, el p-valor es muy elevado, por lo que concluímos que la diferencia tampoco será estadísticamente significativa.

#### *agility_time*

```{r}

outliers <- boxplot.stats(datos$agility_time)$out
outlier_data <- datos %>% filter(agility_time %in% outliers)

datos$x <- 1

ggplot(datos, aes(x = factor(x),y = agility_time)) +
  geom_boxplot(aes(fill = after_stat(..middle..)), color = "#1f3552", outlier.shape = NA, width = 0.4) +
  scale_fill_gradient(low = "#a6cee3", high = "#1f78b4") +  # gradiente según mediana
  geom_jitter(width = 0.15, alpha = 0.4, color = "#404080", size = 2) +  # puntos dispersos
  geom_point(data = outlier_data, aes(y = agility_time), color = "red", size = 3, shape = 16) +  # outliers destacados
  geom_text(data = outlier_data, aes(y = agility_time, label = round(agility_time, 2)), 
            color = "red", vjust = -1, size = 3) +  # etiquetas de outliers
  labs(
    title = "Boxplot Avanzado de agility_time",
    y = "agility_time",
    x = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none"
  )

```

Vemos que esta variable no tiene *outliers*. Por tanto, no haremos el estudio que hicimos para el resto de variables.

### Exploración descriptiva bivariada

Ahora se realizará una exploración descriptiva bivariada. Con esto podremos ver relaciones entre la variable respuesta y los predictores, así como una detección de *outliers* que perjudiquen las relaciones y detectar problemas de multicolinealidad (entre otros aspectos).

#### Relaciones de *performance_index* con los predictores

##### *training_hours*

```{r}

ggplot(datos, aes(x = training_hours, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Training hours",
    y = "Performance index",
    title = "Performance vs Training hours"
  )


```

Vemos que la relación entre estas variables parece lineal, con tendencia creciente. Vamos a ver si existen *outliers* influyentes en la relación.

```{r}

ggplot(datos, aes(training_hours, performance_index)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  stat_ellipse(level = 0.95) +
  theme_minimal()


```
Las observaciones que quedan fuera de la elipse son posibles *outliers* de esta relación. En particular, vamos a ver aquellos influyentes.

```{r}
modelo <- lm(performance_index ~ training_hours, data = datos)
cooks <- cooks.distance(modelo)
which(cooks > 4 / length(cooks))

```
Estos índices podrían influir de forma elevada en el ajuste de la relación lineal.

Vamos a calcular el coeficiente de correlación de Pearson para esta relación.

```{r}

cor(datos$training_hours, datos$performance_index,
    use = "complete.obs", method = "pearson")

```
El coeficiente tiene un valor de 0.5813298, lo cual es bastante elevado. 

De esta manera, la exploración bivariada permitió identificar una relación aproximadamente lineal entre *training_hours* y *performance_index*. No se observaron patrones no lineales marcados, aunque se detectaron varias observaciones con influencia elevada en el ajuste lineal.

##### *match_intensity*

```{r}

ggplot(datos, aes(x = match_intensity, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "match_intensity",
    y = "Performance index",
    title = "Performance vs intensidad del partido"
  )


```

Vemos que no podemos afirmar demasiado sobre esta relación. Vamos a ver si existen *outliers* influyentes en la relación con un gráfico de densidad.


```{r}

ggplot(datos, aes(match_intensity, performance_index)) +
  stat_density_2d(aes(fill = after_stat(level)), geom = "polygon", alpha = 0.6) +
  geom_point(alpha = 0.1) +
  theme_minimal()


```

Las observaciones que quedan fuera de la elipse son posibles *outliers* de esta relación. En particular, vamos a ver aquellos influyentes.

Vamos a calcular el coeficiente de correlación de Spearman para esta relación, ya que no hay linealidad aparente.

```{r}

cor(datos$match_intensity, datos$performance_index,
    use = "complete.obs", method = "spearman")

```
El coeficiente tiene un valor de 0.09848997, lo cual es bastante pequeño, indicando una correlación muy leve. 

De esta manera, la exploración bivariada no permitió identificar una relación clara entre *match_intensity* y *performance_index*, ya que son variables poco correlacionadas y donde no se puede apreciar con claridad el tipo de relación.

##### *fatigue*

```{r}

ggplot(datos, aes(x = fatigue, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Fatigue",
    y = "Performance index",
    title = "Performance vs fatiga"
  )


```

Vemos que la relación entre estas variables parece lineal en 2 trozos. Primero, con una tendencia neutra. Sin embargo, la tendencia a partir del valor 60 de fatiga parece resultar negativa. Es decir, a mayor fatiga (a partir del valor 60), menor rendimiento.

Para corroborarlo, vamos a calcular la media del índice de rendimiento para los jugadores con un valor de fatiga menor que 60, y para aquellos con un valor mayor que 60.

```{r}

cut_fatigue <- cut(datos$fatigue, breaks = c(-Inf, 60, Inf))
tapply(datos$performance_index, cut_fatigue, mean)


```
Vemos que los valores obtenidos son muy dispares. Por ende, vamos a plantear un test para ver si la diferencia es estadísticamente significativa.

```{r}

grupo <- ifelse(datos$fatigue <= 60, "low_mid", "high")
t.test(datos$performance_index ~ grupo)


```
Vemos que el p-valor es muy pequeño, por lo que concluimos que la diferencia de estas medias es estadísticamente significativa.

Vemos un boxplot de ambos grupos en función de su índice de rendimiento.

```{r}

boxplot(datos$performance_index ~ grupo, outline = TRUE)

```

Así, los jugadores con fatiga alta (mayor de 60) presentan un índice de rendimiento mucho menor.

A continuación, vemos a marcar los outliers de la relación.

```{r}
# Crear un subconjunto sin NA ni Inf
datos_clean <- datos[is.finite(datos$fatigue) & is.finite(datos$performance_index), ]

fit <- lowess(datos_clean$fatigue, datos_clean$performance_index)

# O usando loess (más flexible y moderno)
fit_loess <- loess(performance_index ~ fatigue, data = datos_clean)

res <- residuals(fit_loess)
out <- abs(res) > 2 * sd(res)  # umbral exploratorio

plot(datos_clean$fatigue, datos_clean$performance_index)
lines(datos_clean$fatigue, predict(fit_loess), col = "blue", lwd = 2)
points(datos_clean$fatigue[out], datos_clean$performance_index[out],
       pch = 21, bg = "red", cex = 1.2)


```

Los puntos marcados en rojo son los posibles *outliers* de esta relación, que pueden marcar el ajuste.

Por último, vamos a calcular el coeficiente de correlación de Spearman para esta relación, más adecuado debido al resultado analizado.

```{r}

cor(datos$fatigue, datos$performance_index,
    use = "complete.obs", method = "spearman")

```
El coeficiente tiene un valor de -0.2149984, lo cual es razonablemente elevado. Sin embargo, vamos a ver la correlacion en los 2 grupos planteados previamente. Como parecían ser lineales, calcularemos el coeficiente de relación de Pearson.

```{r}

grupo <- ifelse(datos$fatigue <= 60, "low_mid", "high")
cor(datos$fatigue[grupo=="low_mid"], datos$performance_index[grupo=="low_mid"],use = "complete.obs", method="pearson")
cor(datos$fatigue[grupo=="high"], datos$performance_index[grupo=="high"],use = "complete.obs", method="pearson")


```
Así, vemos que la correlación es prácticamente nula para el grupo con fatiga baja, pero razonablemente elevada (inversamente) para el grupo de fatiga elevada.

De esta manera, la exploración bivariada permitió identificar una relación aproximadamente lineal en 2 tramos entre *fatigue* y *performance_index*. Factores como la correlación y la media del valor *performance_index* se ven marcados por este hecho.

##### *sleep_hours*

```{r}

ggplot(datos, aes(x = sleep_hours, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Sleep hours",
    y = "Performance index",
    title = "Performance vs Sleep hours"
  )


```

Vemos que la relación entre estas variables parece lineal, con tendencia creciente. Vamos a ver si existen *outliers* influyentes en la relación.

```{r}

ggplot(datos, aes(sleep_hours, performance_index)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  stat_ellipse(level = 0.95) +
  theme_minimal()


```
Las observaciones que quedan fuera de la elipse son posibles *outliers* de esta relación. En particular, vamos a ver aquellos influyentes.

```{r}
modelo <- lm(performance_index ~ sleep_hours, data = datos)
cooks <- cooks.distance(modelo)
which(cooks > 4 / length(cooks))

```
Estos índices podrían influir de forma elevada en el ajuste de la relación lineal.

Vamos a calcular el coeficiente de correlación de Pearson para esta relación.

```{r}

cor(datos$sleep_hours, datos$performance_index,
    use = "complete.obs", method = "pearson")

```
El coeficiente tiene un valor de 0.1382186, lo cual es ligeramente elevado. 

De esta manera, la exploración bivariada permitió identificar una relación aproximadamente lineal entre *sleep_hours* y *performance_index*. No se observaron patrones no lineales marcados, aunque se detectaron varias observaciones con influencia elevada en el ajuste lineal.

##### *nutrition_score*

```{r}

ggplot(datos, aes(x = nutrition_score, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Nutrition Score",
    y = "Performance index",
    title = "Performance vs Nutrition Score"
  )


```

Vemos que la relación entre estas variables parece lineal, con tendencia neutra, aunque la "nube" de observaciones parece dispersa. Vamos a ver si existen *outliers* influyentes en la relación.

```{r}

ggplot(datos, aes(nutrition_score, performance_index)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  stat_ellipse(level = 0.95) +
  theme_minimal()


```
Las observaciones que quedan fuera de la elipse son posibles *outliers* de esta relación. En particular, vamos a ver aquellos influyentes.

```{r}
modelo <- lm(performance_index ~ nutrition_score, data = datos)
cooks <- cooks.distance(modelo)
which(cooks > 4 / length(cooks))

```
Estos índices podrían influir de forma elevada en el ajuste de la relación lineal.

Vamos a calcular el coeficiente de correlación de Pearson para esta relación.

```{r}

cor(datos$nutrition_score, datos$performance_index,
    use = "complete.obs", method = "pearson")

```
El coeficiente tiene un valor de 0.01274685, lo cual es muy poco. 

De esta manera, la exploración bivariada permitió identificar una relación aproximadamente lineal entre *nutrition_score* y *performance_index*. No se observaron patrones no lineales marcados, aunque se detectaron varias observaciones con influencia elevada en el ajuste lineal. Sin embargo, es importante destacar la práctica incorrelación de ambas variables.

##### *previous_injuries*

```{r}

ggplot(datos, aes(x = previous_injuries, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Previous injuries",
    y = "Performance index",
    title = "Performance vs Previous injuries"
  )


```

Vemos que la relación entre estas variables parece lineal, a pesar de ser difícil encontrar otro tipo de relación al tratarse de una variable entera. Vamos a emplear, por tanto, la transformación en logaritmo que planteamos previamente.

```{r}

ggplot(datos, aes(x = previous_injuries_log, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Previous injuries",
    y = "Performance index",
    title = "Performance vs Previous injuries"
  )

```
Aquí se aprecia mejor la linealidad con tendencia neutra. Por tanto, trabajaremos con esta transformación. A continuación, veremos los *outliers* de la relación.

```{r}

ggplot(datos, aes(previous_injuries_log, performance_index)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  stat_ellipse(level = 0.95) +
  theme_minimal()


```
Las observaciones que quedan fuera de la elipse son posibles *outliers* de esta relación. En particular, vamos a ver aquellos influyentes.

```{r}
modelo <- lm(performance_index ~ previous_injuries_log, data = datos)
cooks <- cooks.distance(modelo)
which(cooks > 4 / length(cooks))

```
Estos índices podrían influir de forma elevada en el ajuste de la relación lineal.

Vamos a calcular el coeficiente de correlación de Pearson para esta relación.

```{r}

cor(datos$previous_injuries_log, datos$performance_index,
    use = "complete.obs", method = "pearson")

```
El coeficiente tiene un valor de 0.01226061, lo cual es muy pequeño. 

De esta manera, la exploración bivariada permitió identificar una relación aproximadamente lineal entre *previous_injuries_log* y *performance_index*, a pesar de su baja correlación. No se observaron patrones no lineales marcados, aunque se detectaron varias observaciones con influencia elevada en el ajuste lineal.

##### *strength_1RM*

```{r}

ggplot(datos, aes(x = strength_1RM, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Strength_1RM",
    y = "Performance index",
    title = "Performance vs Strength_1RM"
  )


```

Vemos que la relación entre estas variables parece lineal, con ligeras desviaciones, que no resultan especialmente llamativas. Vamos a ver si existen *outliers* influyentes en la relación.

```{r}

ggplot(datos, aes(strength_1RM, performance_index)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  stat_ellipse(level = 0.95) +
  theme_minimal()


```
Las observaciones que quedan fuera de la elipse son posibles *outliers* de esta relación. En particular, vamos a ver aquellos influyentes.

```{r}
modelo <- lm(performance_index ~ strength_1RM, data = datos)
cooks <- cooks.distance(modelo)
which(cooks > 4 / length(cooks))

```
Estos índices podrían influir de forma elevada en el ajuste de la relación lineal.

Vamos a calcular el coeficiente de correlación de Pearson para esta relación.

```{r}

cor(datos$strength_1RM, datos$performance_index,
    use = "complete.obs", method = "pearson")

```
El coeficiente tiene un valor de 0.02971936, lo cual es muy poco. 

De esta manera, la exploración bivariada permitió identificar una relación aproximadamente lineal entre *strength_1RM* y *performance_index*, a pesar de su baja correlación. No se observaron patrones no lineales marcados, aunque se detectaron varias observaciones con influencia elevada en el ajuste lineal.

##### *agility_time*

```{r}

ggplot(datos, aes(x = agility_time, y = performance_index)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  labs(
    x = "Agility time",
    y = "Performance index",
    title = "Performance vs Agility time"
  )


```

Vemos que la relación entre estas variables parece lineal, pero con matices. Podemos distinguir un caso similar al de *fatigue*, donde hay un primer tramo lineal de tendencia negativa hasta los 10 segundos, y otro de tendencia neutra de ahí en adelante.

Para corroborarlo, vamos a calcular la media del índice de rendimiento para los jugadores con un valor de *agility_time* menor que 9.75, y para aquellos con un valor mayor

```{r}

cut_agility <- cut(datos$agility_time, breaks = c(-Inf, 9.75, Inf))
tapply(datos$performance_index, cut_agility, mean)


```
Vemos que los valores obtenidos son dispares. Por ende, vamos a plantear un test para ver si la diferencia es estadísticamente significativa.

```{r}

grupo <- ifelse(datos$agility_time <= 9.75, "low", "mid_high")
t.test(datos$performance_index ~ grupo)


```
Vemos que el p-valor es muy pequeño, por lo que concluimos que la diferencia de estas medias es estadísticamente significativa.

Vemos un boxplot de ambos grupos en función de su índice de rendimiento.

```{r}

boxplot(datos$performance_index ~ grupo, outline = TRUE)

```

Así, los jugadores con un tiempo de agilidad bajo (menor que 9.75) presentan un índice de rendimiento mucho mayor que los demás jugadores.

A continuación, vemos a marcar los outliers de la relación.

```{r}
# Crear un subconjunto sin NA ni Inf
datos_clean <- datos[is.finite(datos$agility_time) & is.finite(datos$performance_index), ]

fit <- lowess(datos_clean$agility_time, datos_clean$performance_index)

# O usando loess (más flexible y moderno)
fit_loess <- loess(performance_index ~ agility_time, data = datos_clean)

res <- residuals(fit_loess)
out <- abs(res) > 2 * sd(res)  # umbral exploratorio

plot(datos_clean$agility_time, datos_clean$performance_index)
lines(datos_clean$agility_time, predict(fit_loess), col = "blue", lwd = 2)
points(datos_clean$agility_time[out], datos_clean$performance_index[out],
       pch = 21, bg = "red", cex = 1.2)


```

Los puntos marcados en rojo son los posibles *outliers* de esta relación, que pueden marcar el ajuste.

Por último, vamos a calcular el coeficiente de correlación de Spearman para esta relación, más adecuado debido al resultado analizado.

```{r}

cor(datos$agility_time, datos$performance_index,
    use = "complete.obs", method = "spearman")

```
El coeficiente tiene un valor de -0.0806302, lo cual es razonablemente bajo. Sin embargo, vamos a ver la correlacion en los 2 grupos planteados previamente. Como parecían ser lineales, calcularemos el coeficiente de relación de Pearson.

```{r}

grupo <- ifelse(datos$agility_time <= 9.75, "low", "mid_high")
cor(datos$agility_time[grupo=="low"], datos$performance_index[grupo=="low"],use = "complete.obs", method="pearson")
cor(datos$agility_time[grupo=="mid_high"], datos$performance_index[grupo=="mid_high"],use = "complete.obs", method="pearson")


```
Así, vemos que la correlación es prácticamente nula para el grupo con *agility_time* alto, pero razonablemente elevada (inversamente) para el grupo de *agility_time* bajo.

De esta manera, la exploración bivariada permitió identificar una relación aproximadamente lineal en 2 tramos entre *agility_time* y *performance_index*. Factores como la correlación y la media del valor *performance_index* se ven marcados por este hecho.


#### Relaciones entre predictores

```{r}

predictores <- datos[, c(
  "training_hours", "match_intensity", "fatigue", "sleep_hours",
  "nutrition_score", "previous_injuries", "strength_1Rm", "agility_time"
)]

cor(predictores, use = "complete.obs", method = "spearman")

```

A continuación vemos las correlaciones

```{r}

library(corrplot)

vars <- datos |>
  select(
    performance_index,
    training_hours,
    match_intensity,
    fatigue,
    sleep_hours,
    nutrition_score,
    strength_1RM,
    agility_time,
    injuries_count
  )

corrplot(cor(vars, use = "complete.obs"), method = "color")


```



